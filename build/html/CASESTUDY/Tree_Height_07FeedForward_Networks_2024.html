

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Estimation of tree height using GEDI dataset - Neural Network 1 - 2024 &mdash; Spatial Ecology&#39;s code documentation 0.0.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css?v=572af1d6" />
      <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
      <link rel="stylesheet" type="text/css" href="../_static/nbsphinx-code-cells.css?v=2aa19091" />

  
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=d45e8c67"></script>
      <script src="../_static/doctools.js?v=9bcbadda"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../_static/thebelab-helper.js"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
      <script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
      <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
      <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
      <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Neural Nets (pt.3), Interpretability and Convolutional Neural Networks" href="NNs_pt3_SHAP.html" />
    <link rel="prev" title="Estimation of tree height using GEDI dataset - Neural Network 1" href="Tree_Height_06NeuralNets_pred.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            Spatial Ecology's code documentation
              <img src="../_static/SE_compact.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">COURSE TRAINERS</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../COURSETRAINERS/trainers.html">Spatial Ecology course trainers</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">COURSES AROUND THE WORLD</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../COURSESAROUNDTHEWORLD/course_wcsu_02-04_2021.html">Western Connecticut State University 2021</a></li>
<li class="toctree-l1"><a class="reference internal" href="../COURSESAROUNDTHEWORLD/course_stock_uni_04-05_2021.html">Stockholm University 2021</a></li>
<li class="toctree-l1"><a class="reference internal" href="../COURSESAROUNDTHEWORLD/course_geocomp_ml_04-05_2022.html">GeoComp &amp; ML 2022 course</a></li>
<li class="toctree-l1"><a class="reference internal" href="../COURSESAROUNDTHEWORLD/course_geocomp_modelling_10-11_2022.html">GeoComp &amp; Modelling 2022 course</a></li>
<li class="toctree-l1"><a class="reference internal" href="../COURSESAROUNDTHEWORLD/course_geocomp_ml_04-05_2023.html">GeoComp &amp; ML 2023 course</a></li>
<li class="toctree-l1"><a class="reference internal" href="../COURSESAROUNDTHEWORLD/course_geocomp_ml_04-05_2024.html">GeoComp &amp; ML 2024 course</a></li>
<li class="toctree-l1"><a class="reference internal" href="../COURSESAROUNDTHEWORLD/course_GEO-OPEN-HACK-2024_06_2024.html">GEO-OPEN-HACK-2024</a></li>
<li class="toctree-l1"><a class="reference internal" href="../COURSESAROUNDTHEWORLD/course_geocomp_11-12_2024.html">GeoComp 2024 course</a></li>
<li class="toctree-l1"><a class="reference internal" href="../COURSESAROUNDTHEWORLD/course_geocomp_geoanlysis_04_2025.html">Geo Comp/Analysis 2025 course</a></li>
<li class="toctree-l1"><a class="reference internal" href="../COURSESAROUNDTHEWORLD/course_geocomp_ml_09-11_2025.html">GeoComp &amp; ML 2025 course</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">GEO DATA</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../GEODATA/geomorpho90m/geomorpho90m.html">Geomorpho90m: technical documentation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">LINUX VIRTUAL MACHINE</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../VIRTUALMACHINE/Setting_Ubuntu24.04_for_Spatial_Ecology_course.html">Prepare Ubuntu 24.04 for Spatial Ecology courses</a></li>
<li class="toctree-l1"><a class="reference internal" href="../VIRTUALMACHINE/Setting_Colab_for_Spatial_Ecology_course.html">Prepare Colab for Spatial Ecology courses</a></li>
<li class="toctree-l1"><a class="reference internal" href="../VIRTUALMACHINE/Setting_OSGeoLive_for_Spatial_Ecology_course.html">Prepare OSGeoLive for Spatial Ecology courses</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">WEB SEMINARS</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../WEBSEMINAR/webseminar.html">Raster/Vector Processing using GDAL/OGR</a></li>
<li class="toctree-l1"><a class="reference internal" href="../WEBSEMINAR/webseminar.html#image-processing-using-pktools">Image Processing using Pktools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../WEBSEMINAR/webseminar.html#introduction-to-grass-gis">Introduction to GRASS GIS</a></li>
<li class="toctree-l1"><a class="reference internal" href="../WEBSEMINAR/webseminar.html#geocomputation-with-high-performance-computing">GeoComputation with High Performance Computing</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">BASH</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../BASH/bashintro_osgeo.html">Linux Operation System as a base for Spatial Ecology Computing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../BASH/bashinter_osgeo.html">Manipulate text files in bash</a></li>
<li class="toctree-l1"><a class="reference internal" href="../BASH/bashxargs_osgeo.html">Multi-core bash</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">AWK</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../AWK/awk.html">AWK Tutorial</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">GDAL</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../GDAL/gdal_osgeo.html">Use GDAL/OGR for raster/vector operations - osgeo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../GDAL/gdal_colab.html">Use GDAL/OGR for raster/vector operations - colab</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">PKTOOLS</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../PKTOOLS/pktools_osgeo.html">Use PKTOOLS for raster/vector operations - osgeo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../PKTOOLS/pktools_colab.html">Use PKTOOLS for raster/vector operations - colab</a></li>
<li class="toctree-l1"><a class="reference internal" href="../PKTOOLS/pyjeo_introduction1.html">Introduction to pyjeo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../PKTOOLS/pyjeo_introduction2.html">pyjeo: an open source image processing library in Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="../PKTOOLS/pyjeo_pktools.html">Performing raster and vector operations in Python using pyjeo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../PKTOOLS/pyjeo_upscaling_surf.html">Scaling-up: batch processing on the cluster with pyjeo</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">R</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../R/R_Intro.html">R Introduction</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">PYTHON</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../PYTHON/PythonEnvs.html">Python environments or how to survive to your journey in the geodata space</a></li>
<li class="toctree-l1"><a class="reference internal" href="../PYTHON/Python_Intro.html">Introduction to Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="../PYTHON/Geo_Python.html">Python &amp; GeoComputation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../PYTHON/Python_data_analysis_SM.html">Python data analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../PYTHON/Python_geospatial_data_analysis_SM.html">Python geospatial data analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../PYTHON/RasterIO_Intro.html">RasterIO for dummies: a brief intro to a <em>pythonic</em> raster library</a></li>
<li class="toctree-l1"><a class="reference internal" href="../PYTHON/RasterIO_Intro.html#2.-Preparing-the-dataset-for-next-ML-exercises-via-rasterio">2. Preparing the dataset for next ML exercises via rasterio</a></li>
<li class="toctree-l1"><a class="reference internal" href="../PYTHON/RasterIO_Intro.html#3.-Beyond-the-basics">3. Beyond the basics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../PYTHON/OGCSQL.html">Generalities about OGC Geospatial extensions for SQL</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">GRASS</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../GRASS/grass_intro.html">GRASS Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../GRASS/grass_newproject.html">Start a new GRASS project</a></li>
<li class="toctree-l1"><a class="reference internal" href="../GRASS/grass_hydro.html">Using GRASS for stream-network extraction and basins delineation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../GRASS/grass_hydro_colab.html">Using GRASS for stream-network extraction and basins delineation in Colab</a></li>
<li class="toctree-l1"><a class="reference internal" href="../GRASS/SDM1_MWood_gecomp4GRASS.html">SDM1 : Montane woodcreper - Gecomputation for the Random Forest model using GRASS</a></li>
<li class="toctree-l1"><a class="reference internal" href="../GRASS/SDM1_MWood_GRASSmodel.html">SDM1 : Montane woodcreper - Random Forest Model using GRASS</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">HIGH PERFORMANCE COMPUTING</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../HPC/hpc_setting.html">Geocomputation at High Performance Computing Cluster (HPC)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../HPC/hpc_setting_grass.html">Use of GRASS in HPC</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">ASSIGNMENTS</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../ASSIGNMENTS/assignment_fall2022_solutions.html">Assignments Fall 2022</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">CASE STUDY</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="SDM1_MWood_gecomp.html">SDM1 : Montane woodcreper - Gecomputation</a></li>
<li class="toctree-l1"><a class="reference internal" href="SDM1_MWood_Rmodel.html">SDM1 : Montane woodcreper - Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="SDM1_MWood_gecomp4GRASS.html">SDM1 : Montane woodcreper - Gecomputation for the Random Forest model using GRASS</a></li>
<li class="toctree-l1"><a class="reference internal" href="SDM1_MWood_GRASSmodel.html">SDM1 : Montane woodcreper - Random Forest Model using GRASS</a></li>
<li class="toctree-l1"><a class="reference internal" href="SDM2_Vath_Rmodel.html">SDM2 : Varied Thrush - Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="manipulate_GSIM.html">Manipulate GSIM files</a></li>
<li class="toctree-l1"><a class="reference internal" href="Data_type_GTiff.html">Data type in GTiff</a></li>
<li class="toctree-l1"><a class="reference internal" href="temporal_interpolation.html">Temporal interpolation of landsat images</a></li>
<li class="toctree-l1"><a class="reference internal" href="DTW.html">Dynamic Time Warping</a></li>
<li class="toctree-l1"><a class="reference internal" href="pred_NP.html">Estimating nitrogen and phosphorus concentrations in streams and rivers</a></li>
<li class="toctree-l1"><a class="reference internal" href="NN-day1.html">Estimating nitrogen concentrations in streams and rivers using NN</a></li>
<li class="toctree-l1"><a class="reference internal" href="NN-day2.html">Autoencoder (AE), Variational Autoencoder (VAE) and Generative Adversarial Network (GAN)</a></li>
<li class="toctree-l1"><a class="reference internal" href="NN-day3.html">LSTM Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="Tree_Height_01DataExplore.html">Estimation of tree height using GEDI dataset - Data explore</a></li>
<li class="toctree-l1"><a class="reference internal" href="Tree_Height_02Predictors_extraction.html">Estimation of tree height using GEDI dataset - Predictors extraction at point location</a></li>
<li class="toctree-l1"><a class="reference internal" href="Tree_Height_03RF_pred.html">Estimation of tree height using GEDI dataset - Random Forest prediction</a></li>
<li class="toctree-l1"><a class="reference internal" href="Tree_Height_04SVM_pred_2022.html">Estimation of tree height using GEDI dataset - Support Vector Machine for Regression (SVR) - 2022</a></li>
<li class="toctree-l1"><a class="reference internal" href="Tree_Height_04SVM_pred_2023.html">Estimation of tree height using GEDI dataset - Support Vector Machine for Regression (SVR) - 2023</a></li>
<li class="toctree-l1"><a class="reference internal" href="Tree_Height_04SVM_pred_2024.html">Estimation of tree height using GEDI dataset - Support Vector Machine for Regression (SVR) - 2024</a></li>
<li class="toctree-l1"><a class="reference internal" href="Tree_Height_04SVM_pred_2024.html#Exercise:-explore-the-other-parameters-offered-by-the-SVM-library-and-try-to-make-the-model-better.-Some-suggestions:">Exercise: explore the other parameters offered by the SVM library and try to make the model better. Some suggestions:</a></li>
<li class="toctree-l1"><a class="reference internal" href="Tree_Height_05Perceptron_pred_2022.html">Estimation of tree height using GEDI dataset - Perceptron 1 - 2022</a></li>
<li class="toctree-l1"><a class="reference internal" href="Tree_Height_05Perceptron_intro_2023.html">Estimation of tree height using GEDI dataset - Perceptron 1 - 2023</a></li>
<li class="toctree-l1"><a class="reference internal" href="Tree_Height_05Perceptron_intro_2024.html">Estimation of tree height using GEDI dataset - Perceptron - 2024</a></li>
<li class="toctree-l1"><a class="reference internal" href="Tree_Height_06Perceptron_pred_2023.html">Estimation of tree height using GEDI dataset - Perceptron tree prediction - 2023</a></li>
<li class="toctree-l1"><a class="reference internal" href="Tree_Height_06Perceptron_complete_2024.html">Estimation of tree height using GEDI dataset - Perceptron complete - 2024</a></li>
<li class="toctree-l1"><a class="reference internal" href="Tree_Height_05Perceptron_pred_clean_2022.html">Estimation of tree height using GEDI dataset - Clean Data - Perceptron 2 - 2022</a></li>
<li class="toctree-l1"><a class="reference internal" href="Tree_Height_06NeuralNets_pred.html">Estimation of tree height using GEDI dataset - Neural Network 1</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Estimation of tree height using GEDI dataset - Neural Network 1 - 2024</a></li>
<li class="toctree-l1"><a class="reference internal" href="NNs_pt3_SHAP.html">Neural Nets (pt.3), Interpretability and Convolutional Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="CNN_satelite_2022.html">Using Multi-layer Perceptron and Convolutional Neural Networks for Satellite image classification - 2022.</a></li>
<li class="toctree-l1"><a class="reference internal" href="CNN_satelite_2023.html">Using Multi-layer Perceptron and Convolutional Neural Networks for Satellite image classification - 2023</a></li>
<li class="toctree-l1"><a class="reference internal" href="CNN_satelite_2023.html#Using-CNNs-for-a-image-dataset">Using CNNs for a image dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="foundation_model_IIASA2024.html">Prithvi 100M model</a></li>
<li class="toctree-l1"><a class="reference internal" href="foundation_model_IIASA2024.html#Proposed-exercises">Proposed exercises</a></li>
<li class="toctree-l1"><a class="reference internal" href="NN_Unsupervised_2024.html">Autoencoder (AE), Variational Autoencoder (VAE)</a></li>
<li class="toctree-l1"><a class="reference internal" href="NN_Unsupervised_2024.html#Implementing-an-Autoencoder">Implementing an Autoencoder</a></li>
<li class="toctree-l1"><a class="reference internal" href="NN_Unsupervised_2024.html#Autoencoding-MNIST">Autoencoding MNIST</a></li>
<li class="toctree-l1"><a class="reference internal" href="NN_Unsupervised_2024.html#Section-2">Section 2</a></li>
<li class="toctree-l1"><a class="reference internal" href="NN_Unsupervised_2024.html#Section-3---Generative-Models">Section 3 - Generative Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="LSTMs_tutorial.html">Using LSTM for time-series predictions</a></li>
<li class="toctree-l1"><a class="reference internal" href="CNN_satelite_with_GPT_code_2023.html">Using GPT to implement a Convolutional Neural Networks for Satellite image classification.</a></li>
<li class="toctree-l1"><a class="reference internal" href="Classification_pyjeo_sklearn_2023.html">Classification in Python using pyjeo and sklearn</a></li>
<li class="toctree-l1"><a class="reference internal" href="GEEviaPython_2023.html">Google Earth Engine use via Python, containers and other mythical beasts</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Students Projects</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../STUDENTSPROJECTS/index.html">1. 2021 SWEDEN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../STUDENTSPROJECTS/index.html#matera">2. 2022 MATERA</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">OUTDOOR</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../OUTDOOR/outdoor_orientering.html">Do not get lost in the wilderness</a></li>
<li class="toctree-l1"><a class="reference internal" href="../OUTDOOR/outdoor_info.html">Shelter locations close to Gioia del Colle (BA)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../OUTDOOR/bike_accomodation.html">Accomodation in Gioia del Colle (BA)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../OUTDOOR/puglia_discover.html">Discover Puglia by bike!</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">TALKS</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../TALKS/intelligent_modelling.html">Intelligent modelling in time and space: combine GeoComputation and Machine Learning for  environmental application.</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">ADMIN</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../ADMIN/00_pktools_gdrive_install.html">Install pktools on the gdrive and be able to use from any Colab</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ADMIN/video.html">Video tips</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ADMIN/Compiling_OTB.html">Compiling OTB from source</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Spatial Ecology's code documentation</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="index.html">&lt;no title&gt;</a></li>
      <li class="breadcrumb-item active">Estimation of tree height using GEDI dataset - Neural Network 1 - 2024</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/CASESTUDY/Tree_Height_07FeedForward_Networks_2024.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="Estimation-of-tree-height-using-GEDI-dataset---Neural-Network-1---2024">
<h1>Estimation of tree height using GEDI dataset - Neural Network 1 - 2024<a class="headerlink" href="#Estimation-of-tree-height-using-GEDI-dataset---Neural-Network-1---2024" title="Link to this heading"></a></h1>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>cd /media/sf_LVM_shared/my_SE_data/exercise/
wget https://raw.githubusercontent.com/selvaje/SE_docs/master/source/CASESTUDY/Tree_Height_07FeedForward_Networks_2024.ipynb
source $HOME/venv/bin/activate
pip3 install torch torchvision torchaudio
</pre></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">Packages</span>

<span class="sd">conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch</span>
<span class="sd">conda install -c anaconda scikit-learn</span>
<span class="sd">conda install pandas</span>
<span class="sd">&#39;&#39;&#39;</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">scipy</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">r2_score</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">pearsonr</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Fix random seeds.</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">seed</span><span class="o">=</span><span class="mi">31</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Using device:&#39;</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/gpfs/gibbs/project/dijk/ahf38/conda_envs/geo_comp2/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html
  from .autonotebook import tqdm as notebook_tqdm
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Using device: cuda
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">predictors</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;./tree_height_2/txt/eu_x_y_height_predictors_select.txt&quot;</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s2">&quot; &quot;</span><span class="p">,</span>  <span class="n">index_col</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.max_columns&#39;</span><span class="p">,</span><span class="kc">None</span><span class="p">)</span>
<span class="c1"># change column name</span>
<span class="n">predictors</span> <span class="o">=</span> <span class="n">predictors</span><span class="o">.</span><span class="n">rename</span><span class="p">({</span><span class="s1">&#39;dev-magnitude&#39;</span><span class="p">:</span><span class="s1">&#39;devmagnitude&#39;</span><span class="p">}</span> <span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="s1">&#39;columns&#39;</span><span class="p">)</span>
<span class="n">predictors</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ID</th>
      <th>X</th>
      <th>Y</th>
      <th>h</th>
      <th>BLDFIE_WeigAver</th>
      <th>CECSOL_WeigAver</th>
      <th>CHELSA_bio18</th>
      <th>CHELSA_bio4</th>
      <th>convergence</th>
      <th>cti</th>
      <th>devmagnitude</th>
      <th>eastness</th>
      <th>elev</th>
      <th>forestheight</th>
      <th>glad_ard_SVVI_max</th>
      <th>glad_ard_SVVI_med</th>
      <th>glad_ard_SVVI_min</th>
      <th>northness</th>
      <th>ORCDRC_WeigAver</th>
      <th>outlet_dist_dw_basin</th>
      <th>SBIO3_Isothermality_5_15cm</th>
      <th>SBIO4_Temperature_Seasonality_5_15cm</th>
      <th>treecover</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>6.050001</td>
      <td>49.727499</td>
      <td>3139.00</td>
      <td>1540</td>
      <td>13</td>
      <td>2113</td>
      <td>5893</td>
      <td>-10.486560</td>
      <td>-238043120</td>
      <td>1.158417</td>
      <td>0.069094</td>
      <td>353.983124</td>
      <td>23</td>
      <td>276.871094</td>
      <td>46.444092</td>
      <td>347.665405</td>
      <td>0.042500</td>
      <td>9</td>
      <td>780403</td>
      <td>19.798992</td>
      <td>440.672211</td>
      <td>85</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>6.050002</td>
      <td>49.922155</td>
      <td>1454.75</td>
      <td>1491</td>
      <td>12</td>
      <td>1993</td>
      <td>5912</td>
      <td>33.274361</td>
      <td>-208915344</td>
      <td>-1.755341</td>
      <td>0.269112</td>
      <td>267.511688</td>
      <td>19</td>
      <td>-49.526367</td>
      <td>19.552734</td>
      <td>-130.541748</td>
      <td>0.182780</td>
      <td>16</td>
      <td>772777</td>
      <td>20.889412</td>
      <td>457.756195</td>
      <td>85</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>6.050002</td>
      <td>48.602377</td>
      <td>853.50</td>
      <td>1521</td>
      <td>17</td>
      <td>2124</td>
      <td>5983</td>
      <td>0.045293</td>
      <td>-137479792</td>
      <td>1.908780</td>
      <td>-0.016055</td>
      <td>389.751160</td>
      <td>21</td>
      <td>93.257324</td>
      <td>50.743652</td>
      <td>384.522461</td>
      <td>0.036253</td>
      <td>14</td>
      <td>898820</td>
      <td>20.695877</td>
      <td>481.879700</td>
      <td>62</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>6.050009</td>
      <td>48.151979</td>
      <td>3141.00</td>
      <td>1526</td>
      <td>16</td>
      <td>2569</td>
      <td>6130</td>
      <td>-33.654274</td>
      <td>-267223072</td>
      <td>0.965787</td>
      <td>0.067767</td>
      <td>380.207703</td>
      <td>27</td>
      <td>542.401367</td>
      <td>202.264160</td>
      <td>386.156738</td>
      <td>0.005139</td>
      <td>15</td>
      <td>831824</td>
      <td>19.375000</td>
      <td>479.410278</td>
      <td>85</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>6.050010</td>
      <td>49.588410</td>
      <td>2065.25</td>
      <td>1547</td>
      <td>14</td>
      <td>2108</td>
      <td>5923</td>
      <td>27.493824</td>
      <td>-107809368</td>
      <td>-0.162624</td>
      <td>0.014065</td>
      <td>308.042786</td>
      <td>25</td>
      <td>136.048340</td>
      <td>146.835205</td>
      <td>198.127441</td>
      <td>0.028847</td>
      <td>17</td>
      <td>796962</td>
      <td>18.777500</td>
      <td>457.880066</td>
      <td>85</td>
    </tr>
    <tr>
      <th>5</th>
      <td>6</td>
      <td>6.050014</td>
      <td>48.608456</td>
      <td>1246.50</td>
      <td>1515</td>
      <td>19</td>
      <td>2124</td>
      <td>6010</td>
      <td>-1.602039</td>
      <td>17384282</td>
      <td>1.447979</td>
      <td>-0.018912</td>
      <td>364.527100</td>
      <td>18</td>
      <td>221.339844</td>
      <td>247.387207</td>
      <td>480.387939</td>
      <td>0.042747</td>
      <td>14</td>
      <td>897945</td>
      <td>19.398880</td>
      <td>474.331329</td>
      <td>62</td>
    </tr>
    <tr>
      <th>6</th>
      <td>7</td>
      <td>6.050016</td>
      <td>48.571401</td>
      <td>2938.75</td>
      <td>1520</td>
      <td>19</td>
      <td>2169</td>
      <td>6147</td>
      <td>27.856503</td>
      <td>-66516432</td>
      <td>-1.073956</td>
      <td>0.002280</td>
      <td>254.679596</td>
      <td>19</td>
      <td>125.250488</td>
      <td>87.865234</td>
      <td>160.696777</td>
      <td>0.037254</td>
      <td>11</td>
      <td>908426</td>
      <td>20.170450</td>
      <td>476.414520</td>
      <td>96</td>
    </tr>
    <tr>
      <th>7</th>
      <td>8</td>
      <td>6.050019</td>
      <td>49.921613</td>
      <td>3294.75</td>
      <td>1490</td>
      <td>12</td>
      <td>1995</td>
      <td>5912</td>
      <td>22.102139</td>
      <td>-297770784</td>
      <td>-1.402633</td>
      <td>0.309765</td>
      <td>294.927765</td>
      <td>26</td>
      <td>-86.729492</td>
      <td>-145.584229</td>
      <td>-190.062988</td>
      <td>0.222435</td>
      <td>15</td>
      <td>772784</td>
      <td>20.855963</td>
      <td>457.195404</td>
      <td>86</td>
    </tr>
    <tr>
      <th>8</th>
      <td>9</td>
      <td>6.050020</td>
      <td>48.822645</td>
      <td>1623.50</td>
      <td>1554</td>
      <td>18</td>
      <td>1973</td>
      <td>6138</td>
      <td>18.496584</td>
      <td>-25336536</td>
      <td>-0.800016</td>
      <td>0.010370</td>
      <td>240.493759</td>
      <td>22</td>
      <td>-51.470703</td>
      <td>-245.886719</td>
      <td>172.074707</td>
      <td>0.004428</td>
      <td>8</td>
      <td>839132</td>
      <td>21.812290</td>
      <td>496.231110</td>
      <td>64</td>
    </tr>
    <tr>
      <th>9</th>
      <td>10</td>
      <td>6.050024</td>
      <td>49.847522</td>
      <td>1400.00</td>
      <td>1521</td>
      <td>15</td>
      <td>2187</td>
      <td>5886</td>
      <td>-5.660453</td>
      <td>-278652608</td>
      <td>1.477951</td>
      <td>-0.068720</td>
      <td>376.671143</td>
      <td>12</td>
      <td>277.297363</td>
      <td>273.141846</td>
      <td>-138.895996</td>
      <td>0.098817</td>
      <td>13</td>
      <td>768873</td>
      <td>21.137711</td>
      <td>466.976685</td>
      <td>70</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bins</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">predictors</span><span class="p">[</span><span class="s1">&#39;h&#39;</span><span class="p">]),</span><span class="nb">max</span><span class="p">(</span><span class="n">predictors</span><span class="p">[</span><span class="s1">&#39;h&#39;</span><span class="p">]),</span><span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">((</span><span class="n">predictors</span><span class="p">[</span><span class="s1">&#39;h&#39;</span><span class="p">]),</span><span class="n">bins</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_4_0.png" src="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_4_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">predictors_sel</span> <span class="o">=</span> <span class="n">predictors</span><span class="o">.</span><span class="n">loc</span><span class="p">[(</span><span class="n">predictors</span><span class="p">[</span><span class="s1">&#39;h&#39;</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">7000</span><span class="p">)</span>  <span class="p">]</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">100000</span><span class="p">)</span>
<span class="n">predictors_sel</span><span class="o">.</span><span class="n">insert</span> <span class="p">(</span> <span class="mi">4</span><span class="p">,</span> <span class="s1">&#39;hm&#39;</span> <span class="p">,</span>  <span class="n">predictors_sel</span><span class="p">[</span><span class="s1">&#39;h&#39;</span><span class="p">]</span><span class="o">/</span><span class="mi">100</span> <span class="p">)</span> <span class="c1"># add a culumn of heigh in meter</span>
<span class="nb">len</span><span class="p">(</span><span class="n">predictors_sel</span><span class="p">)</span>
<span class="n">predictors_sel</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ID</th>
      <th>X</th>
      <th>Y</th>
      <th>h</th>
      <th>hm</th>
      <th>BLDFIE_WeigAver</th>
      <th>CECSOL_WeigAver</th>
      <th>CHELSA_bio18</th>
      <th>CHELSA_bio4</th>
      <th>convergence</th>
      <th>cti</th>
      <th>devmagnitude</th>
      <th>eastness</th>
      <th>elev</th>
      <th>forestheight</th>
      <th>glad_ard_SVVI_max</th>
      <th>glad_ard_SVVI_med</th>
      <th>glad_ard_SVVI_min</th>
      <th>northness</th>
      <th>ORCDRC_WeigAver</th>
      <th>outlet_dist_dw_basin</th>
      <th>SBIO3_Isothermality_5_15cm</th>
      <th>SBIO4_Temperature_Seasonality_5_15cm</th>
      <th>treecover</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>706027</th>
      <td>706028</td>
      <td>8.142676</td>
      <td>49.473039</td>
      <td>2192.25</td>
      <td>21.9225</td>
      <td>1506</td>
      <td>12</td>
      <td>1951</td>
      <td>6332</td>
      <td>33.326790</td>
      <td>-123652624</td>
      <td>-0.773497</td>
      <td>-0.098556</td>
      <td>264.291107</td>
      <td>20</td>
      <td>-124.898438</td>
      <td>-166.341064</td>
      <td>-138.483887</td>
      <td>-0.033544</td>
      <td>11</td>
      <td>670987</td>
      <td>17.290588</td>
      <td>461.153107</td>
      <td>85</td>
    </tr>
    <tr>
      <th>311603</th>
      <td>311604</td>
      <td>7.013065</td>
      <td>49.703660</td>
      <td>343.00</td>
      <td>3.4300</td>
      <td>1384</td>
      <td>12</td>
      <td>2356</td>
      <td>5661</td>
      <td>-25.426283</td>
      <td>-245676352</td>
      <td>2.994771</td>
      <td>0.006374</td>
      <td>654.403931</td>
      <td>5</td>
      <td>1108.965820</td>
      <td>746.828125</td>
      <td>661.711182</td>
      <td>-0.050651</td>
      <td>21</td>
      <td>817030</td>
      <td>23.282337</td>
      <td>414.707062</td>
      <td>75</td>
    </tr>
    <tr>
      <th>678298</th>
      <td>678299</td>
      <td>7.976119</td>
      <td>48.864294</td>
      <td>2000.75</td>
      <td>20.0075</td>
      <td>1509</td>
      <td>11</td>
      <td>2297</td>
      <td>6539</td>
      <td>39.657501</td>
      <td>712222848</td>
      <td>-1.524940</td>
      <td>0.000425</td>
      <td>128.738113</td>
      <td>14</td>
      <td>633.487549</td>
      <td>503.831787</td>
      <td>528.050537</td>
      <td>0.004593</td>
      <td>9</td>
      <td>760668</td>
      <td>19.584862</td>
      <td>497.715546</td>
      <td>78</td>
    </tr>
    <tr>
      <th>574438</th>
      <td>574439</td>
      <td>7.675911</td>
      <td>48.970574</td>
      <td>2450.00</td>
      <td>24.5000</td>
      <td>1519</td>
      <td>14</td>
      <td>2393</td>
      <td>6316</td>
      <td>25.545052</td>
      <td>45228972</td>
      <td>-0.508573</td>
      <td>0.016525</td>
      <td>269.375000</td>
      <td>26</td>
      <td>844.863037</td>
      <td>247.661865</td>
      <td>466.090088</td>
      <td>0.038866</td>
      <td>8</td>
      <td>812785</td>
      <td>17.917974</td>
      <td>465.584839</td>
      <td>99</td>
    </tr>
    <tr>
      <th>629555</th>
      <td>629556</td>
      <td>7.832786</td>
      <td>49.434854</td>
      <td>1655.75</td>
      <td>16.5575</td>
      <td>1501</td>
      <td>11</td>
      <td>1894</td>
      <td>6390</td>
      <td>-1.106694</td>
      <td>-329245536</td>
      <td>0.693265</td>
      <td>-0.175357</td>
      <td>305.205170</td>
      <td>25</td>
      <td>69.657959</td>
      <td>59.458008</td>
      <td>-60.963135</td>
      <td>-0.101222</td>
      <td>8</td>
      <td>641305</td>
      <td>18.297518</td>
      <td>458.570312</td>
      <td>85</td>
    </tr>
    <tr>
      <th>24779</th>
      <td>24780</td>
      <td>6.120472</td>
      <td>49.359733</td>
      <td>2131.00</td>
      <td>21.3100</td>
      <td>1537</td>
      <td>18</td>
      <td>1997</td>
      <td>6106</td>
      <td>-5.047365</td>
      <td>-169883136</td>
      <td>-1.281423</td>
      <td>-0.060032</td>
      <td>194.458313</td>
      <td>23</td>
      <td>118.437012</td>
      <td>52.685547</td>
      <td>278.717041</td>
      <td>0.020525</td>
      <td>6</td>
      <td>764430</td>
      <td>21.795704</td>
      <td>478.565186</td>
      <td>87</td>
    </tr>
    <tr>
      <th>1131458</th>
      <td>1131459</td>
      <td>9.422926</td>
      <td>49.091389</td>
      <td>2697.25</td>
      <td>26.9725</td>
      <td>1524</td>
      <td>11</td>
      <td>2720</td>
      <td>6380</td>
      <td>48.204334</td>
      <td>207834704</td>
      <td>-0.667805</td>
      <td>-0.053927</td>
      <td>439.546326</td>
      <td>24</td>
      <td>120.082275</td>
      <td>98.926758</td>
      <td>-173.800537</td>
      <td>0.030877</td>
      <td>7</td>
      <td>861697</td>
      <td>18.758785</td>
      <td>467.858246</td>
      <td>87</td>
    </tr>
    <tr>
      <th>55515</th>
      <td>55516</td>
      <td>6.236967</td>
      <td>49.744940</td>
      <td>1998.00</td>
      <td>19.9800</td>
      <td>1522</td>
      <td>12</td>
      <td>2220</td>
      <td>5868</td>
      <td>13.136125</td>
      <td>-241940960</td>
      <td>0.944569</td>
      <td>0.107422</td>
      <td>360.844513</td>
      <td>25</td>
      <td>35.600098</td>
      <td>79.752441</td>
      <td>287.183594</td>
      <td>-0.032823</td>
      <td>20</td>
      <td>743874</td>
      <td>19.420862</td>
      <td>445.672028</td>
      <td>85</td>
    </tr>
    <tr>
      <th>768590</th>
      <td>768591</td>
      <td>8.487635</td>
      <td>48.828276</td>
      <td>2386.00</td>
      <td>23.8600</td>
      <td>1498</td>
      <td>17</td>
      <td>2951</td>
      <td>6406</td>
      <td>6.318799</td>
      <td>1560159</td>
      <td>0.223795</td>
      <td>-0.078058</td>
      <td>438.207855</td>
      <td>25</td>
      <td>-58.626709</td>
      <td>-98.312988</td>
      <td>-243.423584</td>
      <td>-0.035823</td>
      <td>15</td>
      <td>756191</td>
      <td>20.880857</td>
      <td>475.791046</td>
      <td>85</td>
    </tr>
    <tr>
      <th>290850</th>
      <td>290851</td>
      <td>6.965025</td>
      <td>49.931148</td>
      <td>357.00</td>
      <td>3.5700</td>
      <td>1501</td>
      <td>14</td>
      <td>1955</td>
      <td>6328</td>
      <td>31.918867</td>
      <td>-176713840</td>
      <td>-1.974737</td>
      <td>0.077967</td>
      <td>145.118774</td>
      <td>20</td>
      <td>97.752930</td>
      <td>123.906006</td>
      <td>-152.656982</td>
      <td>0.136252</td>
      <td>13</td>
      <td>619283</td>
      <td>20.002157</td>
      <td>472.414703</td>
      <td>85</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bins</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">predictors_sel</span><span class="p">[</span><span class="s1">&#39;hm&#39;</span><span class="p">]),</span><span class="nb">max</span><span class="p">(</span><span class="n">predictors_sel</span><span class="p">[</span><span class="s1">&#39;hm&#39;</span><span class="p">]),</span><span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">((</span><span class="n">predictors_sel</span><span class="p">[</span><span class="s1">&#39;hm&#39;</span><span class="p">]),</span><span class="n">bins</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_6_0.png" src="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_6_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># What we are trying to beat</span>
<span class="n">y_true</span> <span class="o">=</span> <span class="n">predictors_sel</span><span class="p">[</span><span class="s1">&#39;h&#39;</span><span class="p">]</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">predictors_sel</span><span class="p">[</span><span class="s1">&#39;forestheight&#39;</span><span class="p">]</span>

<span class="n">slope</span><span class="p">,</span> <span class="n">intercept</span><span class="p">,</span> <span class="n">r_value</span><span class="p">,</span> <span class="n">p_value</span><span class="p">,</span> <span class="n">std_err</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">linregress</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_true</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_true</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Prediction&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;True&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;slope: </span><span class="si">{:.4f}</span><span class="s1">, r_value: </span><span class="si">{:.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">slope</span><span class="p">,</span> <span class="n">r_value</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<br/></pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_7_0.png" src="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_7_0.png" />
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tree_height</span> <span class="o">=</span> <span class="n">predictors_sel</span><span class="p">[</span><span class="s1">&#39;hm&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">predictors_sel</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;ID&#39;</span><span class="p">,</span><span class="s1">&#39;h&#39;</span><span class="p">,</span> <span class="s1">&#39;hm&#39;</span><span class="p">,</span><span class="s1">&#39;forestheight&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Explore the raw data</span>
<span class="n">n_plots_x</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])))</span>
<span class="n">n_plots_y</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;data.shape[1]: </span><span class="si">{}</span><span class="s1">, n_plots_x: </span><span class="si">{}</span><span class="s1">,n_plots_y: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">n_plots_x</span><span class="p">,</span><span class="n">n_plots_y</span><span class="p">))</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">n_plots_x</span><span class="p">,</span> <span class="n">n_plots_y</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">facecolor</span><span class="o">=</span><span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
<span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
<span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
data.shape[1]: 20, n_plots_x: 5,n_plots_y: 4
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_9_1.png" src="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_9_1.png" />
</div>
</div>
<p>Since our target variable is highly skewed, let’s use a power transformation to make it more normal-like. Check this <a class="reference external" href="https://scikit-learn.org/stable/auto_examples/preprocessing/plot_map_data_to_normal.html#sphx-glr-auto-examples-preprocessing-plot-map-data-to-normal-py">blog</a> for other commonly used power transformations</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">QuantileTransformer</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">MinMaxScaler</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>
<span class="n">qt</span> <span class="o">=</span> <span class="n">QuantileTransformer</span><span class="p">(</span>
    <span class="n">n_quantiles</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">output_distribution</span><span class="o">=</span><span class="s2">&quot;normal&quot;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>

<span class="n">tree_height</span> <span class="o">=</span> <span class="n">qt</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">tree_height</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">scaler_tree</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">(</span><span class="n">feature_range</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">tree_height</span> <span class="o">=</span> <span class="n">scaler_tree</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">tree_height</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
<span class="n">tree_height</span> <span class="o">=</span><span class="n">tree_height</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">tree_height</span><span class="p">,</span><span class="mf">0.99</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">tree_height</span><span class="p">,</span><span class="mi">50</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(array([2.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,
        0.000e+00, 0.000e+00, 0.000e+00, 5.000e+00, 1.060e+02, 1.900e+02,
        3.670e+02, 4.730e+02, 7.720e+02, 1.152e+03, 1.490e+03, 2.502e+03,
        3.213e+03, 4.129e+03, 5.043e+03, 6.236e+03, 6.872e+03, 8.668e+03,
        8.159e+03, 8.413e+03, 8.249e+03, 7.757e+03, 6.651e+03, 5.468e+03,
        3.980e+03, 3.010e+03, 2.322e+03, 1.635e+03, 1.269e+03, 8.220e+02,
        4.610e+02, 2.880e+02, 1.350e+02, 9.700e+01, 3.300e+01, 1.200e+01,
        9.000e+00, 0.000e+00, 1.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,
        0.000e+00, 9.000e+00]),
 array([-2.25692362e+00, -2.16664668e+00, -2.07636973e+00, -1.98609279e+00,
        -1.89581584e+00, -1.80553890e+00, -1.71526195e+00, -1.62498501e+00,
        -1.53470806e+00, -1.44443112e+00, -1.35415417e+00, -1.26387723e+00,
        -1.17360028e+00, -1.08332334e+00, -9.93046394e-01, -9.02769449e-01,
        -8.12492504e-01, -7.22215559e-01, -6.31938615e-01, -5.41661670e-01,
        -4.51384725e-01, -3.61107780e-01, -2.70830835e-01, -1.80553890e-01,
        -9.02769449e-02,  4.44089210e-16,  9.02769449e-02,  1.80553890e-01,
         2.70830835e-01,  3.61107780e-01,  4.51384725e-01,  5.41661670e-01,
         6.31938615e-01,  7.22215559e-01,  8.12492504e-01,  9.02769449e-01,
         9.93046394e-01,  1.08332334e+00,  1.17360028e+00,  1.26387723e+00,
         1.35415417e+00,  1.44443112e+00,  1.53470806e+00,  1.62498501e+00,
         1.71526195e+00,  1.80553890e+00,  1.89581584e+00,  1.98609279e+00,
         2.07636973e+00,  2.16664668e+00,  2.25692362e+00]),
 &lt;BarContainer object of 50 artists&gt;)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_11_1.png" src="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_11_1.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Normalize the data</span>
<span class="n">scaler_data</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>
<span class="n">data_transformed</span> <span class="o">=</span> <span class="n">scaler_data</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">n_plots_x</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])))</span>
<span class="n">n_plots_y</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;data.shape[1]: </span><span class="si">{}</span><span class="s1">, n_plots_x: </span><span class="si">{}</span><span class="s1">,n_plots_y: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">n_plots_x</span><span class="p">,</span><span class="n">n_plots_y</span><span class="p">))</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">n_plots_x</span><span class="p">,</span> <span class="n">n_plots_y</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">facecolor</span><span class="o">=</span><span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
<span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">data_transformed</span><span class="p">[:,</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
<span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
data.shape[1]: 20, n_plots_x: 5,n_plots_y: 4
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_12_1.png" src="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_12_1.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Let&#39;s use all the data as one big minibatch</span>

<span class="c1">#Split the data</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">data_transformed</span><span class="p">,</span><span class="n">tree_height</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.30</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;X_train.shape: </span><span class="si">{}</span><span class="s1">, X_test.shape: </span><span class="si">{}</span><span class="s1">, y_train.shape: </span><span class="si">{}</span><span class="s1">, y_test.shape: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_test</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;X_train.min: </span><span class="si">{}</span><span class="s1">, X_test.min: </span><span class="si">{}</span><span class="s1">, y_train.min: </span><span class="si">{}</span><span class="s1">, y_test.min: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">X_test</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">y_train</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">y_test</span><span class="o">.</span><span class="n">min</span><span class="p">()))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;X_train.max: </span><span class="si">{}</span><span class="s1">, X_test.max: </span><span class="si">{}</span><span class="s1">, y_train.max: </span><span class="si">{}</span><span class="s1">, y_test.max: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">X_test</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">y_train</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">y_test</span><span class="o">.</span><span class="n">max</span><span class="p">()))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
X_train.shape: torch.Size([70000, 20]), X_test.shape: torch.Size([30000, 20]), y_train.shape: torch.Size([70000]), y_test.shape: torch.Size([30000])
X_train.min: 0.0, X_test.min: 0.0, y_train.min: -2.2569236755371094, y_test.min: -2.2569236755371094
X_train.max: 1.0, X_test.max: 1.0, y_train.max: 2.2569236755371094, y_test.max: 2.2569236755371094
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Try with FF</span>
<span class="k">class</span><span class="w"> </span><span class="nc">Feedforward</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Feedforward</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_size</span> <span class="o">=</span> <span class="n">input_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span>  <span class="o">=</span> <span class="n">hidden_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tanh</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">()</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">hidden</span><span class="p">))</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">hidden</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">output</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># model.train()</span>
<span class="n">epoch</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">hid_dim_range</span> <span class="o">=</span> <span class="p">[</span><span class="mi">128</span><span class="p">,</span><span class="mi">256</span><span class="p">,</span><span class="mi">512</span><span class="p">]</span>
<span class="n">lr_range</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.75</span><span class="p">,</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.01</span><span class="p">,</span><span class="mf">0.05</span><span class="p">]</span>

<span class="k">for</span> <span class="n">hid_dim</span> <span class="ow">in</span> <span class="n">hid_dim_range</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">lr</span> <span class="ow">in</span> <span class="n">lr_range</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">hid_dim: </span><span class="si">{}</span><span class="s1">, lr: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">hid_dim</span><span class="p">,</span> <span class="n">lr</span><span class="p">))</span>
        <span class="k">if</span> <span class="s1">&#39;model&#39;</span> <span class="ow">in</span> <span class="nb">globals</span><span class="p">():</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Deleting previous model&#39;</span><span class="p">)</span>
            <span class="k">del</span> <span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">Feedforward</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">hid_dim</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span> <span class="o">=</span> <span class="n">lr</span><span class="p">)</span>

        <span class="n">all_loss_train</span><span class="o">=</span><span class="p">[]</span>
        <span class="n">all_loss_val</span><span class="o">=</span><span class="p">[]</span>
        <span class="n">all_r_train</span><span class="o">=</span><span class="p">[]</span>
        <span class="n">all_r_val</span><span class="o">=</span><span class="p">[]</span>

        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epoch</span><span class="p">):</span>
            <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="c1"># Forward pass</span>
            <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
            <span class="c1"># Compute Loss</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">y_pred</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">y_train</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>

            <span class="c1"># Backward pass</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="n">all_loss_train</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
            <span class="n">y_pred</span> <span class="o">=</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">r_value_train</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">linregress</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
            <span class="n">all_r_train</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">r_value_train</span><span class="p">)</span>

            <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X_test</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
                <span class="c1"># Compute Loss</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">y_pred</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">y_test</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
                <span class="n">all_loss_val</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

                <span class="n">y_pred</span> <span class="o">=</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
                <span class="n">slope</span><span class="p">,</span> <span class="n">intercept</span><span class="p">,</span> <span class="n">r_value</span><span class="p">,</span> <span class="n">p_value</span><span class="p">,</span> <span class="n">std_err</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">linregress</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
                <span class="n">all_r_val</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">r_value</span><span class="p">)</span>
                <span class="c1"># r_value2 = pearsonr(y_pred, y_test)[0]</span>

                <span class="k">if</span> <span class="n">epoch</span><span class="o">%</span><span class="k">500</span>==0:
                    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch </span><span class="si">{}</span><span class="s1">, train_loss: </span><span class="si">{:.4f}</span><span class="s1">, val_loss: </span><span class="si">{:.4f}</span><span class="s1">, r_value: </span><span class="si">{:.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span><span class="n">all_loss_train</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span><span class="n">all_loss_val</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span><span class="n">r_value</span><span class="p">))</span>

        <span class="n">fig</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
        <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">all_loss_train</span><span class="p">))</span>
        <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">all_loss_val</span><span class="p">))</span>
        <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>

        <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">all_r_train</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">all_r_val</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Pearson Corr&#39;</span><span class="p">)</span>

        <span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_test</span><span class="o">.</span><span class="n">cpu</span><span class="p">())</span>
        <span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Prediction&#39;</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;True&#39;</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;slope: </span><span class="si">{:.4f}</span><span class="s1">, r_value: </span><span class="si">{:.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">slope</span><span class="p">,</span> <span class="n">r_value</span><span class="p">))</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

hid_dim: 128, lr: 0.75
Epoch 0, train_loss: 0.1980, val_loss: 0.2900, r_value: 0.1720
Epoch 500, train_loss: 0.1546, val_loss: 0.1568, r_value: 0.4467
Epoch 1000, train_loss: 0.1511, val_loss: 0.1527, r_value: 0.4671
Epoch 1500, train_loss: 0.1482, val_loss: 0.1495, r_value: 0.4792
Epoch 2000, train_loss: 0.1463, val_loss: 0.1477, r_value: 0.4872
Epoch 2500, train_loss: 0.1407, val_loss: 0.1433, r_value: 0.4914
Epoch 3000, train_loss: 0.1458, val_loss: 0.1472, r_value: 0.4819
Epoch 3500, train_loss: 0.1445, val_loss: 0.1462, r_value: 0.4892
Epoch 4000, train_loss: 0.1436, val_loss: 0.1454, r_value: 0.4950
Epoch 4500, train_loss: 0.1426, val_loss: 0.1438, r_value: 0.5006
Epoch 5000, train_loss: 0.1389, val_loss: 0.1423, r_value: 0.5012
Epoch 5500, train_loss: 0.1377, val_loss: 0.1394, r_value: 0.5113
Epoch 6000, train_loss: 0.1382, val_loss: 0.1422, r_value: 0.5141
Epoch 6500, train_loss: 0.1336, val_loss: 0.1358, r_value: 0.5133
Epoch 7000, train_loss: 0.1338, val_loss: 0.1368, r_value: 0.5164
Epoch 7500, train_loss: 0.1378, val_loss: 0.1417, r_value: 0.5148
Epoch 8000, train_loss: 0.1392, val_loss: 0.1430, r_value: 0.5201
Epoch 8500, train_loss: 0.1382, val_loss: 0.1420, r_value: 0.5211
Epoch 9000, train_loss: 0.1376, val_loss: 0.1403, r_value: 0.5209
Epoch 9500, train_loss: 0.1366, val_loss: 0.1403, r_value: 0.5226
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_15_1.png" src="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_15_1.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

hid_dim: 128, lr: 0.5
Deleting previous model
Epoch 0, train_loss: 0.1866, val_loss: 0.1999, r_value: 0.3091
Epoch 500, train_loss: 0.1477, val_loss: 0.1487, r_value: 0.4653
Epoch 1000, train_loss: 0.1440, val_loss: 0.1456, r_value: 0.4816
Epoch 1500, train_loss: 0.1419, val_loss: 0.1436, r_value: 0.4917
Epoch 2000, train_loss: 0.1403, val_loss: 0.1421, r_value: 0.4993
Epoch 2500, train_loss: 0.1391, val_loss: 0.1409, r_value: 0.5051
Epoch 3000, train_loss: 0.1377, val_loss: 0.1395, r_value: 0.5096
Epoch 3500, train_loss: 0.1371, val_loss: 0.1390, r_value: 0.5098
Epoch 4000, train_loss: 0.1368, val_loss: 0.1389, r_value: 0.5144
Epoch 4500, train_loss: 0.1380, val_loss: 0.1401, r_value: 0.5093
Epoch 5000, train_loss: 0.1360, val_loss: 0.1386, r_value: 0.5160
Epoch 5500, train_loss: 0.1337, val_loss: 0.1358, r_value: 0.5164
Epoch 6000, train_loss: 0.1358, val_loss: 0.1387, r_value: 0.5192
Epoch 6500, train_loss: 0.1350, val_loss: 0.1380, r_value: 0.5205
Epoch 7000, train_loss: 0.1338, val_loss: 0.1367, r_value: 0.5217
Epoch 7500, train_loss: 0.1321, val_loss: 0.1355, r_value: 0.5164
Epoch 8000, train_loss: 0.1341, val_loss: 0.1377, r_value: 0.5230
Epoch 8500, train_loss: 0.1334, val_loss: 0.1369, r_value: 0.5225
Epoch 9000, train_loss: 0.1308, val_loss: 0.1349, r_value: 0.5198
Epoch 9500, train_loss: 0.1303, val_loss: 0.1349, r_value: 0.5200
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_15_3.png" src="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_15_3.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

hid_dim: 128, lr: 0.1
Deleting previous model
Epoch 0, train_loss: 0.1887, val_loss: 0.1855, r_value: 0.0150
Epoch 500, train_loss: 0.1459, val_loss: 0.1473, r_value: 0.4486
Epoch 1000, train_loss: 0.1443, val_loss: 0.1458, r_value: 0.4577
Epoch 1500, train_loss: 0.1433, val_loss: 0.1448, r_value: 0.4634
Epoch 2000, train_loss: 0.1430, val_loss: 0.1444, r_value: 0.4679
Epoch 2500, train_loss: 0.1423, val_loss: 0.1437, r_value: 0.4719
Epoch 3000, train_loss: 0.1417, val_loss: 0.1431, r_value: 0.4754
Epoch 3500, train_loss: 0.1412, val_loss: 0.1426, r_value: 0.4786
Epoch 4000, train_loss: 0.1406, val_loss: 0.1420, r_value: 0.4817
Epoch 4500, train_loss: 0.1401, val_loss: 0.1415, r_value: 0.4845
Epoch 5000, train_loss: 0.1397, val_loss: 0.1411, r_value: 0.4872
Epoch 5500, train_loss: 0.1392, val_loss: 0.1407, r_value: 0.4896
Epoch 6000, train_loss: 0.1388, val_loss: 0.1403, r_value: 0.4920
Epoch 6500, train_loss: 0.1383, val_loss: 0.1399, r_value: 0.4942
Epoch 7000, train_loss: 0.1380, val_loss: 0.1395, r_value: 0.4962
Epoch 7500, train_loss: 0.1376, val_loss: 0.1392, r_value: 0.4981
Epoch 8000, train_loss: 0.1372, val_loss: 0.1389, r_value: 0.4999
Epoch 8500, train_loss: 0.1369, val_loss: 0.1386, r_value: 0.5016
Epoch 9000, train_loss: 0.1365, val_loss: 0.1383, r_value: 0.5031
Epoch 9500, train_loss: 0.1362, val_loss: 0.1380, r_value: 0.5045
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_15_5.png" src="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_15_5.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

hid_dim: 128, lr: 0.01
Deleting previous model
Epoch 0, train_loss: 0.1791, val_loss: 0.1808, r_value: 0.3447
Epoch 500, train_loss: 0.1681, val_loss: 0.1699, r_value: 0.3934
Epoch 1000, train_loss: 0.1578, val_loss: 0.1595, r_value: 0.4126
Epoch 1500, train_loss: 0.1514, val_loss: 0.1532, r_value: 0.4245
Epoch 2000, train_loss: 0.1488, val_loss: 0.1505, r_value: 0.4325
Epoch 2500, train_loss: 0.1476, val_loss: 0.1492, r_value: 0.4380
Epoch 3000, train_loss: 0.1469, val_loss: 0.1485, r_value: 0.4418
Epoch 3500, train_loss: 0.1464, val_loss: 0.1480, r_value: 0.4448
Epoch 4000, train_loss: 0.1461, val_loss: 0.1475, r_value: 0.4471
Epoch 4500, train_loss: 0.1457, val_loss: 0.1472, r_value: 0.4491
Epoch 5000, train_loss: 0.1455, val_loss: 0.1469, r_value: 0.4509
Epoch 5500, train_loss: 0.1452, val_loss: 0.1467, r_value: 0.4524
Epoch 6000, train_loss: 0.1450, val_loss: 0.1465, r_value: 0.4537
Epoch 6500, train_loss: 0.1448, val_loss: 0.1463, r_value: 0.4548
Epoch 7000, train_loss: 0.1447, val_loss: 0.1461, r_value: 0.4558
Epoch 7500, train_loss: 0.1445, val_loss: 0.1459, r_value: 0.4567
Epoch 8000, train_loss: 0.1444, val_loss: 0.1458, r_value: 0.4575
Epoch 8500, train_loss: 0.1443, val_loss: 0.1457, r_value: 0.4582
Epoch 9000, train_loss: 0.1442, val_loss: 0.1456, r_value: 0.4589
Epoch 9500, train_loss: 0.1441, val_loss: 0.1455, r_value: 0.4595
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_15_7.png" src="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_15_7.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

hid_dim: 128, lr: 0.05
Deleting previous model
Epoch 0, train_loss: 0.1842, val_loss: 0.1845, r_value: 0.0583
Epoch 500, train_loss: 0.1472, val_loss: 0.1486, r_value: 0.4409
Epoch 1000, train_loss: 0.1458, val_loss: 0.1472, r_value: 0.4490
Epoch 1500, train_loss: 0.1451, val_loss: 0.1465, r_value: 0.4534
Epoch 2000, train_loss: 0.1445, val_loss: 0.1459, r_value: 0.4567
Epoch 2500, train_loss: 0.1441, val_loss: 0.1455, r_value: 0.4592
Epoch 3000, train_loss: 0.1437, val_loss: 0.1451, r_value: 0.4614
Epoch 3500, train_loss: 0.1433, val_loss: 0.1448, r_value: 0.4634
Epoch 4000, train_loss: 0.1430, val_loss: 0.1444, r_value: 0.4654
Epoch 4500, train_loss: 0.1427, val_loss: 0.1441, r_value: 0.4676
Epoch 5000, train_loss: 0.1423, val_loss: 0.1437, r_value: 0.4696
Epoch 5500, train_loss: 0.1420, val_loss: 0.1434, r_value: 0.4716
Epoch 6000, train_loss: 0.1416, val_loss: 0.1430, r_value: 0.4737
Epoch 6500, train_loss: 0.1413, val_loss: 0.1427, r_value: 0.4757
Epoch 7000, train_loss: 0.1409, val_loss: 0.1423, r_value: 0.4776
Epoch 7500, train_loss: 0.1406, val_loss: 0.1420, r_value: 0.4796
Epoch 8000, train_loss: 0.1402, val_loss: 0.1417, r_value: 0.4815
Epoch 8500, train_loss: 0.1399, val_loss: 0.1413, r_value: 0.4833
Epoch 9000, train_loss: 0.1396, val_loss: 0.1410, r_value: 0.4850
Epoch 9500, train_loss: 0.1393, val_loss: 0.1407, r_value: 0.4866
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_15_9.png" src="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_15_9.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

hid_dim: 256, lr: 0.75
Deleting previous model
Epoch 0, train_loss: 0.1870, val_loss: 0.2367, r_value: 0.0894
Epoch 500, train_loss: 0.1555, val_loss: 0.1558, r_value: 0.4674
Epoch 1000, train_loss: 0.1504, val_loss: 0.1517, r_value: 0.4843
Epoch 1500, train_loss: 0.1471, val_loss: 0.1489, r_value: 0.4943
Epoch 2000, train_loss: 0.1444, val_loss: 0.1456, r_value: 0.5017
Epoch 2500, train_loss: 0.1436, val_loss: 0.1441, r_value: 0.5048
Epoch 3000, train_loss: 0.1441, val_loss: 0.1448, r_value: 0.5066
Epoch 3500, train_loss: 0.1403, val_loss: 0.1427, r_value: 0.5131
Epoch 4000, train_loss: 0.1394, val_loss: 0.1422, r_value: 0.5156
Epoch 4500, train_loss: 0.1385, val_loss: 0.1416, r_value: 0.5178
Epoch 5000, train_loss: 0.1377, val_loss: 0.1411, r_value: 0.5197
Epoch 5500, train_loss: 0.1371, val_loss: 0.1407, r_value: 0.5214
Epoch 6000, train_loss: 0.1365, val_loss: 0.1404, r_value: 0.5229
Epoch 6500, train_loss: 0.1361, val_loss: 0.1402, r_value: 0.5241
Epoch 7000, train_loss: 0.1356, val_loss: 0.1400, r_value: 0.5252
Epoch 7500, train_loss: 0.1352, val_loss: 0.1399, r_value: 0.5262
Epoch 8000, train_loss: 0.1348, val_loss: 0.1399, r_value: 0.5270
Epoch 8500, train_loss: 0.1345, val_loss: 0.1399, r_value: 0.5277
Epoch 9000, train_loss: 0.1342, val_loss: 0.1400, r_value: 0.5284
Epoch 9500, train_loss: 0.1338, val_loss: 0.1401, r_value: 0.5289
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_15_11.png" src="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_15_11.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

hid_dim: 256, lr: 0.5
Deleting previous model
Epoch 0, train_loss: 0.1936, val_loss: 0.3296, r_value: 0.2721
Epoch 500, train_loss: 0.1466, val_loss: 0.1482, r_value: 0.4627
Epoch 1000, train_loss: 0.1427, val_loss: 0.1440, r_value: 0.4830
Epoch 1500, train_loss: 0.1407, val_loss: 0.1422, r_value: 0.4936
Epoch 2000, train_loss: 0.1393, val_loss: 0.1410, r_value: 0.5011
Epoch 2500, train_loss: 0.1380, val_loss: 0.1399, r_value: 0.5062
Epoch 3000, train_loss: 0.1369, val_loss: 0.1392, r_value: 0.5100
Epoch 3500, train_loss: 0.1348, val_loss: 0.1377, r_value: 0.5107
Epoch 4000, train_loss: 0.1340, val_loss: 0.1358, r_value: 0.5176
Epoch 4500, train_loss: 0.1344, val_loss: 0.1375, r_value: 0.5164
Epoch 5000, train_loss: 0.1360, val_loss: 0.1410, r_value: 0.5194
Epoch 5500, train_loss: 0.1333, val_loss: 0.1354, r_value: 0.5185
Epoch 6000, train_loss: 0.1341, val_loss: 0.1375, r_value: 0.5242
Epoch 6500, train_loss: 0.1342, val_loss: 0.1379, r_value: 0.5253
Epoch 7000, train_loss: 0.1312, val_loss: 0.1348, r_value: 0.5262
Epoch 7500, train_loss: 0.1301, val_loss: 0.1340, r_value: 0.5241
Epoch 8000, train_loss: 0.1322, val_loss: 0.1366, r_value: 0.5278
Epoch 8500, train_loss: 0.1335, val_loss: 0.1368, r_value: 0.5280
Epoch 9000, train_loss: 0.1322, val_loss: 0.1373, r_value: 0.5289
Epoch 9500, train_loss: 0.1326, val_loss: 0.1379, r_value: 0.5293
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_15_13.png" src="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_15_13.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

hid_dim: 256, lr: 0.1
Deleting previous model
Epoch 0, train_loss: 0.1813, val_loss: 0.1823, r_value: 0.1569
Epoch 500, train_loss: 0.1457, val_loss: 0.1469, r_value: 0.4549
Epoch 1000, train_loss: 0.1439, val_loss: 0.1452, r_value: 0.4630
Epoch 1500, train_loss: 0.1429, val_loss: 0.1442, r_value: 0.4684
Epoch 2000, train_loss: 0.1421, val_loss: 0.1434, r_value: 0.4733
Epoch 2500, train_loss: 0.1412, val_loss: 0.1425, r_value: 0.4780
Epoch 3000, train_loss: 0.1405, val_loss: 0.1419, r_value: 0.4824
Epoch 3500, train_loss: 0.1399, val_loss: 0.1413, r_value: 0.4863
Epoch 4000, train_loss: 0.1393, val_loss: 0.1407, r_value: 0.4898
Epoch 4500, train_loss: 0.1386, val_loss: 0.1401, r_value: 0.4931
Epoch 5000, train_loss: 0.1381, val_loss: 0.1396, r_value: 0.4960
Epoch 5500, train_loss: 0.1376, val_loss: 0.1391, r_value: 0.4986
Epoch 6000, train_loss: 0.1371, val_loss: 0.1387, r_value: 0.5009
Epoch 6500, train_loss: 0.1366, val_loss: 0.1383, r_value: 0.5031
Epoch 7000, train_loss: 0.1361, val_loss: 0.1379, r_value: 0.5051
Epoch 7500, train_loss: 0.1357, val_loss: 0.1376, r_value: 0.5068
Epoch 8000, train_loss: 0.1354, val_loss: 0.1373, r_value: 0.5083
Epoch 8500, train_loss: 0.1350, val_loss: 0.1370, r_value: 0.5097
Epoch 9000, train_loss: 0.1347, val_loss: 0.1367, r_value: 0.5109
Epoch 9500, train_loss: 0.1344, val_loss: 0.1365, r_value: 0.5120
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_15_15.png" src="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_15_15.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

hid_dim: 256, lr: 0.01
Deleting previous model
Epoch 0, train_loss: 0.1809, val_loss: 0.1824, r_value: 0.2568
Epoch 500, train_loss: 0.1574, val_loss: 0.1590, r_value: 0.4312
Epoch 1000, train_loss: 0.1492, val_loss: 0.1507, r_value: 0.4361
Epoch 1500, train_loss: 0.1473, val_loss: 0.1487, r_value: 0.4412
Epoch 2000, train_loss: 0.1465, val_loss: 0.1480, r_value: 0.4450
Epoch 2500, train_loss: 0.1460, val_loss: 0.1475, r_value: 0.4476
Epoch 3000, train_loss: 0.1457, val_loss: 0.1471, r_value: 0.4498
Epoch 3500, train_loss: 0.1454, val_loss: 0.1468, r_value: 0.4518
Epoch 4000, train_loss: 0.1451, val_loss: 0.1465, r_value: 0.4536
Epoch 4500, train_loss: 0.1448, val_loss: 0.1462, r_value: 0.4551
Epoch 5000, train_loss: 0.1446, val_loss: 0.1460, r_value: 0.4564
Epoch 5500, train_loss: 0.1444, val_loss: 0.1458, r_value: 0.4576
Epoch 6000, train_loss: 0.1442, val_loss: 0.1456, r_value: 0.4587
Epoch 6500, train_loss: 0.1440, val_loss: 0.1454, r_value: 0.4598
Epoch 7000, train_loss: 0.1439, val_loss: 0.1453, r_value: 0.4607
Epoch 7500, train_loss: 0.1437, val_loss: 0.1451, r_value: 0.4616
Epoch 8000, train_loss: 0.1436, val_loss: 0.1450, r_value: 0.4624
Epoch 8500, train_loss: 0.1434, val_loss: 0.1448, r_value: 0.4631
Epoch 9000, train_loss: 0.1433, val_loss: 0.1447, r_value: 0.4638
Epoch 9500, train_loss: 0.1432, val_loss: 0.1446, r_value: 0.4645
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_15_17.png" src="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_15_17.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

hid_dim: 256, lr: 0.05
Deleting previous model
Epoch 0, train_loss: 0.1823, val_loss: 0.1836, r_value: 0.1037
Epoch 500, train_loss: 0.1465, val_loss: 0.1480, r_value: 0.4446
Epoch 1000, train_loss: 0.1450, val_loss: 0.1465, r_value: 0.4536
Epoch 1500, train_loss: 0.1441, val_loss: 0.1456, r_value: 0.4588
Epoch 2000, train_loss: 0.1435, val_loss: 0.1449, r_value: 0.4626
Epoch 2500, train_loss: 0.1429, val_loss: 0.1444, r_value: 0.4659
Epoch 3000, train_loss: 0.1424, val_loss: 0.1439, r_value: 0.4689
Epoch 3500, train_loss: 0.1419, val_loss: 0.1434, r_value: 0.4717
Epoch 4000, train_loss: 0.1414, val_loss: 0.1429, r_value: 0.4743
Epoch 4500, train_loss: 0.1410, val_loss: 0.1425, r_value: 0.4768
Epoch 5000, train_loss: 0.1406, val_loss: 0.1421, r_value: 0.4791
Epoch 5500, train_loss: 0.1402, val_loss: 0.1417, r_value: 0.4814
Epoch 6000, train_loss: 0.1398, val_loss: 0.1413, r_value: 0.4834
Epoch 6500, train_loss: 0.1394, val_loss: 0.1410, r_value: 0.4854
Epoch 7000, train_loss: 0.1390, val_loss: 0.1406, r_value: 0.4873
Epoch 7500, train_loss: 0.1387, val_loss: 0.1403, r_value: 0.4889
Epoch 8000, train_loss: 0.1384, val_loss: 0.1400, r_value: 0.4905
Epoch 8500, train_loss: 0.1381, val_loss: 0.1398, r_value: 0.4921
Epoch 9000, train_loss: 0.1381, val_loss: 0.1400, r_value: 0.4935
Epoch 9500, train_loss: 0.1379, val_loss: 0.1399, r_value: 0.4949
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_15_19.png" src="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_15_19.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

hid_dim: 512, lr: 0.75
Deleting previous model
Epoch 0, train_loss: 0.1908, val_loss: 0.6607, r_value: 0.0161
Epoch 500, train_loss: 0.1560, val_loss: 0.1566, r_value: 0.4662
Epoch 1000, train_loss: 0.1496, val_loss: 0.1512, r_value: 0.4841
Epoch 1500, train_loss: 0.1467, val_loss: 0.1486, r_value: 0.4953
Epoch 2000, train_loss: 0.1444, val_loss: 0.1468, r_value: 0.4998
Epoch 2500, train_loss: 0.1431, val_loss: 0.1453, r_value: 0.5035
Epoch 3000, train_loss: 0.1420, val_loss: 0.1442, r_value: 0.5070
Epoch 3500, train_loss: 0.1410, val_loss: 0.1433, r_value: 0.5102
Epoch 4000, train_loss: 0.1402, val_loss: 0.1427, r_value: 0.5128
Epoch 4500, train_loss: 0.1395, val_loss: 0.1422, r_value: 0.5151
Epoch 5000, train_loss: 0.1389, val_loss: 0.1419, r_value: 0.5172
Epoch 5500, train_loss: 0.1383, val_loss: 0.1416, r_value: 0.5189
Epoch 6000, train_loss: 0.1378, val_loss: 0.1415, r_value: 0.5204
Epoch 6500, train_loss: 0.1373, val_loss: 0.1413, r_value: 0.5220
Epoch 7000, train_loss: 0.1368, val_loss: 0.1412, r_value: 0.5232
Epoch 7500, train_loss: 0.1364, val_loss: 0.1412, r_value: 0.5244
Epoch 8000, train_loss: 0.1360, val_loss: 0.1412, r_value: 0.5253
Epoch 8500, train_loss: 0.1357, val_loss: 0.1413, r_value: 0.5261
Epoch 9000, train_loss: 0.1353, val_loss: 0.1413, r_value: 0.5269
Epoch 9500, train_loss: 0.1348, val_loss: 0.1413, r_value: 0.5277
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_15_21.png" src="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_15_21.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

hid_dim: 512, lr: 0.5
Deleting previous model
Epoch 0, train_loss: 0.1871, val_loss: 0.3020, r_value: 0.2117
Epoch 500, train_loss: 0.1485, val_loss: 0.1495, r_value: 0.4665
Epoch 1000, train_loss: 0.1436, val_loss: 0.1453, r_value: 0.4839
Epoch 1500, train_loss: 0.1409, val_loss: 0.1429, r_value: 0.4947
Epoch 2000, train_loss: 0.1392, val_loss: 0.1414, r_value: 0.5034
Epoch 2500, train_loss: 0.1379, val_loss: 0.1402, r_value: 0.5100
Epoch 3000, train_loss: 0.1368, val_loss: 0.1394, r_value: 0.5144
Epoch 3500, train_loss: 0.1359, val_loss: 0.1387, r_value: 0.5176
Epoch 4000, train_loss: 0.1353, val_loss: 0.1384, r_value: 0.5199
Epoch 4500, train_loss: 0.1343, val_loss: 0.1377, r_value: 0.5220
Epoch 5000, train_loss: 0.1340, val_loss: 0.1377, r_value: 0.5236
Epoch 5500, train_loss: 0.1338, val_loss: 0.1382, r_value: 0.5249
Epoch 6000, train_loss: 0.1330, val_loss: 0.1375, r_value: 0.5262
Epoch 6500, train_loss: 0.1318, val_loss: 0.1363, r_value: 0.5274
Epoch 7000, train_loss: 0.1324, val_loss: 0.1377, r_value: 0.5281
Epoch 7500, train_loss: 0.1291, val_loss: 0.1341, r_value: 0.5288
Epoch 8000, train_loss: 0.1319, val_loss: 0.1378, r_value: 0.5297
Epoch 8500, train_loss: 0.1315, val_loss: 0.1377, r_value: 0.5305
Epoch 9000, train_loss: 0.1300, val_loss: 0.1362, r_value: 0.5311
Epoch 9500, train_loss: 0.1315, val_loss: 0.1383, r_value: 0.5313
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_15_23.png" src="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_15_23.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

hid_dim: 512, lr: 0.1
Deleting previous model
Epoch 0, train_loss: 0.1875, val_loss: 0.1850, r_value: 0.2663
Epoch 500, train_loss: 0.1452, val_loss: 0.1465, r_value: 0.4566
Epoch 1000, train_loss: 0.1435, val_loss: 0.1448, r_value: 0.4658
Epoch 1500, train_loss: 0.1424, val_loss: 0.1436, r_value: 0.4730
Epoch 2000, train_loss: 0.1414, val_loss: 0.1427, r_value: 0.4791
Epoch 2500, train_loss: 0.1405, val_loss: 0.1418, r_value: 0.4842
Epoch 3000, train_loss: 0.1397, val_loss: 0.1411, r_value: 0.4886
Epoch 3500, train_loss: 0.1390, val_loss: 0.1405, r_value: 0.4925
Epoch 4000, train_loss: 0.1383, val_loss: 0.1399, r_value: 0.4960
Epoch 4500, train_loss: 0.1377, val_loss: 0.1393, r_value: 0.4992
Epoch 5000, train_loss: 0.1371, val_loss: 0.1388, r_value: 0.5020
Epoch 5500, train_loss: 0.1365, val_loss: 0.1383, r_value: 0.5046
Epoch 6000, train_loss: 0.1359, val_loss: 0.1379, r_value: 0.5068
Epoch 6500, train_loss: 0.1355, val_loss: 0.1374, r_value: 0.5088
Epoch 7000, train_loss: 0.1350, val_loss: 0.1371, r_value: 0.5106
Epoch 7500, train_loss: 0.1346, val_loss: 0.1368, r_value: 0.5121
Epoch 8000, train_loss: 0.1342, val_loss: 0.1365, r_value: 0.5134
Epoch 8500, train_loss: 0.1339, val_loss: 0.1362, r_value: 0.5145
Epoch 9000, train_loss: 0.1336, val_loss: 0.1360, r_value: 0.5155
Epoch 9500, train_loss: 0.1333, val_loss: 0.1358, r_value: 0.5164
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_15_25.png" src="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_15_25.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

hid_dim: 512, lr: 0.01
Deleting previous model
Epoch 0, train_loss: 0.1902, val_loss: 0.1894, r_value: 0.0326
Epoch 500, train_loss: 0.1530, val_loss: 0.1546, r_value: 0.4256
Epoch 1000, train_loss: 0.1480, val_loss: 0.1496, r_value: 0.4372
Epoch 1500, train_loss: 0.1466, val_loss: 0.1481, r_value: 0.4441
Epoch 2000, train_loss: 0.1458, val_loss: 0.1473, r_value: 0.4485
Epoch 2500, train_loss: 0.1453, val_loss: 0.1468, r_value: 0.4517
Epoch 3000, train_loss: 0.1449, val_loss: 0.1464, r_value: 0.4541
Epoch 3500, train_loss: 0.1446, val_loss: 0.1461, r_value: 0.4559
Epoch 4000, train_loss: 0.1443, val_loss: 0.1458, r_value: 0.4574
Epoch 4500, train_loss: 0.1441, val_loss: 0.1456, r_value: 0.4587
Epoch 5000, train_loss: 0.1439, val_loss: 0.1454, r_value: 0.4598
Epoch 5500, train_loss: 0.1438, val_loss: 0.1453, r_value: 0.4607
Epoch 6000, train_loss: 0.1436, val_loss: 0.1451, r_value: 0.4616
Epoch 6500, train_loss: 0.1435, val_loss: 0.1450, r_value: 0.4625
Epoch 7000, train_loss: 0.1433, val_loss: 0.1448, r_value: 0.4632
Epoch 7500, train_loss: 0.1432, val_loss: 0.1447, r_value: 0.4640
Epoch 8000, train_loss: 0.1431, val_loss: 0.1446, r_value: 0.4647
Epoch 8500, train_loss: 0.1430, val_loss: 0.1445, r_value: 0.4654
Epoch 9000, train_loss: 0.1429, val_loss: 0.1443, r_value: 0.4661
Epoch 9500, train_loss: 0.1427, val_loss: 0.1442, r_value: 0.4668
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_15_27.png" src="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_15_27.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

hid_dim: 512, lr: 0.05
Deleting previous model
Epoch 0, train_loss: 0.1858, val_loss: 0.1832, r_value: 0.1049
Epoch 500, train_loss: 0.1454, val_loss: 0.1469, r_value: 0.4513
Epoch 1000, train_loss: 0.1441, val_loss: 0.1456, r_value: 0.4589
Epoch 1500, train_loss: 0.1434, val_loss: 0.1449, r_value: 0.4627
Epoch 2000, train_loss: 0.1429, val_loss: 0.1444, r_value: 0.4658
Epoch 2500, train_loss: 0.1430, val_loss: 0.1447, r_value: 0.4687
Epoch 3000, train_loss: 0.1425, val_loss: 0.1442, r_value: 0.4715
Epoch 3500, train_loss: 0.1420, val_loss: 0.1437, r_value: 0.4741
Epoch 4000, train_loss: 0.1416, val_loss: 0.1433, r_value: 0.4766
Epoch 4500, train_loss: 0.1412, val_loss: 0.1429, r_value: 0.4791
Epoch 5000, train_loss: 0.1407, val_loss: 0.1425, r_value: 0.4815
Epoch 5500, train_loss: 0.1403, val_loss: 0.1421, r_value: 0.4838
Epoch 6000, train_loss: 0.1399, val_loss: 0.1418, r_value: 0.4859
Epoch 6500, train_loss: 0.1395, val_loss: 0.1414, r_value: 0.4880
Epoch 7000, train_loss: 0.1392, val_loss: 0.1411, r_value: 0.4899
Epoch 7500, train_loss: 0.1388, val_loss: 0.1408, r_value: 0.4917
Epoch 8000, train_loss: 0.1385, val_loss: 0.1405, r_value: 0.4934
Epoch 8500, train_loss: 0.1381, val_loss: 0.1402, r_value: 0.4950
Epoch 9000, train_loss: 0.1378, val_loss: 0.1399, r_value: 0.4965
Epoch 9500, train_loss: 0.1375, val_loss: 0.1397, r_value: 0.4980
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_15_29.png" src="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_15_29.png" />
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Try deeper FF</span>
<span class="k">class</span><span class="w"> </span><span class="nc">Feedforward</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Feedforward</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_size</span> <span class="o">=</span> <span class="n">input_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span>  <span class="o">=</span> <span class="n">hidden_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc4</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc5</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tanh</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">()</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">hidden</span><span class="p">))</span>
        <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">hidden</span><span class="p">))</span>
        <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc4</span><span class="p">(</span><span class="n">hidden</span><span class="p">))</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc5</span><span class="p">(</span><span class="n">hidden</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">output</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># model.train()</span>
<span class="n">epoch</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">hid_dim_range</span> <span class="o">=</span> <span class="p">[</span><span class="mi">128</span><span class="p">,</span><span class="mi">256</span><span class="p">,</span><span class="mi">512</span><span class="p">]</span>
<span class="n">lr_range</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.75</span><span class="p">,</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.01</span><span class="p">,</span><span class="mf">0.05</span><span class="p">]</span>

<span class="k">for</span> <span class="n">hid_dim</span> <span class="ow">in</span> <span class="n">hid_dim_range</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">lr</span> <span class="ow">in</span> <span class="n">lr_range</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">hid_dim: </span><span class="si">{}</span><span class="s1">, lr: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">hid_dim</span><span class="p">,</span> <span class="n">lr</span><span class="p">))</span>
        <span class="k">if</span> <span class="s1">&#39;model&#39;</span> <span class="ow">in</span> <span class="nb">globals</span><span class="p">():</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Deleting previous model&#39;</span><span class="p">)</span>
            <span class="k">del</span> <span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">Feedforward</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">hid_dim</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span> <span class="o">=</span> <span class="n">lr</span><span class="p">)</span>

        <span class="n">all_loss_train</span><span class="o">=</span><span class="p">[]</span>
        <span class="n">all_loss_val</span><span class="o">=</span><span class="p">[]</span>
        <span class="n">all_r_train</span><span class="o">=</span><span class="p">[]</span>
        <span class="n">all_r_val</span><span class="o">=</span><span class="p">[]</span>

        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epoch</span><span class="p">):</span>
            <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="c1"># Forward pass</span>
            <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
            <span class="c1"># Compute Loss</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">y_pred</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">y_train</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>

            <span class="c1"># Backward pass</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="n">all_loss_train</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
            <span class="n">y_pred</span> <span class="o">=</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">r_value_train</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">linregress</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
            <span class="n">all_r_train</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">r_value_train</span><span class="p">)</span>

            <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X_test</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
                <span class="c1"># Compute Loss</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">y_pred</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">y_test</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
                <span class="n">all_loss_val</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

                <span class="n">y_pred</span> <span class="o">=</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
                <span class="n">slope</span><span class="p">,</span> <span class="n">intercept</span><span class="p">,</span> <span class="n">r_value</span><span class="p">,</span> <span class="n">p_value</span><span class="p">,</span> <span class="n">std_err</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">linregress</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
                <span class="n">all_r_val</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">r_value</span><span class="p">)</span>

                <span class="k">if</span> <span class="n">epoch</span><span class="o">%</span><span class="k">500</span>==0:
                    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch </span><span class="si">{}</span><span class="s1">, train_loss: </span><span class="si">{:.4f}</span><span class="s1">, val_loss: </span><span class="si">{:.4f}</span><span class="s1">, r_value: </span><span class="si">{:.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span><span class="n">all_loss_train</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span><span class="n">all_loss_val</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span><span class="n">r_value</span><span class="p">))</span>

        <span class="n">fig</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
        <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">all_loss_train</span><span class="p">))</span>
        <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">all_loss_val</span><span class="p">))</span>
        <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>

        <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">all_r_train</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">all_r_val</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Pearson Corr&#39;</span><span class="p">)</span>

        <span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_test</span><span class="o">.</span><span class="n">cpu</span><span class="p">())</span>
        <span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Prediction&#39;</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;True&#39;</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;slope: </span><span class="si">{:.4f}</span><span class="s1">, r_value: </span><span class="si">{:.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">slope</span><span class="p">,</span> <span class="n">r_value</span><span class="p">))</span>

        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

hid_dim: 128, lr: 0.75
Deleting previous model
Epoch 0, train_loss: 0.1823, val_loss: 0.1838, r_value: 0.1924
Epoch 500, train_loss: 0.1588, val_loss: 0.1564, r_value: 0.4524
Epoch 1000, train_loss: 0.1560, val_loss: 0.1555, r_value: 0.4598
Epoch 1500, train_loss: 0.1536, val_loss: 0.1543, r_value: 0.4662
Epoch 2000, train_loss: 0.1520, val_loss: 0.1534, r_value: 0.4733
Epoch 2500, train_loss: 0.1498, val_loss: 0.1517, r_value: 0.4793
Epoch 3000, train_loss: 0.1482, val_loss: 0.1502, r_value: 0.4841
Epoch 3500, train_loss: 0.1476, val_loss: 0.1488, r_value: 0.4887
Epoch 4000, train_loss: 0.1470, val_loss: 0.1470, r_value: 0.4950
Epoch 4500, train_loss: 0.1510, val_loss: 0.1525, r_value: 0.4764
Epoch 5000, train_loss: 0.1450, val_loss: 0.1477, r_value: 0.4957
Epoch 5500, train_loss: 0.1444, val_loss: 0.1428, r_value: 0.5038
Epoch 6000, train_loss: 0.1442, val_loss: 0.1469, r_value: 0.5053
Epoch 6500, train_loss: 0.1384, val_loss: 0.1416, r_value: 0.5059
Epoch 7000, train_loss: 0.1424, val_loss: 0.1456, r_value: 0.5063
Epoch 7500, train_loss: 0.1357, val_loss: 0.1392, r_value: 0.5046
Epoch 8000, train_loss: 0.1445, val_loss: 0.1436, r_value: 0.4978
Epoch 8500, train_loss: 0.1462, val_loss: 0.1375, r_value: 0.5068
Epoch 9000, train_loss: 0.1364, val_loss: 0.1365, r_value: 0.5146
Epoch 9500, train_loss: 0.1341, val_loss: 0.1361, r_value: 0.5157
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_17_1.png" src="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_17_1.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

hid_dim: 128, lr: 0.5
Deleting previous model
Epoch 0, train_loss: 0.1824, val_loss: 0.1840, r_value: 0.2352
Epoch 500, train_loss: 0.1489, val_loss: 0.1511, r_value: 0.4465
Epoch 1000, train_loss: 0.1466, val_loss: 0.1482, r_value: 0.4627
Epoch 1500, train_loss: 0.1450, val_loss: 0.1463, r_value: 0.4735
Epoch 2000, train_loss: 0.1434, val_loss: 0.1446, r_value: 0.4804
Epoch 2500, train_loss: 0.1425, val_loss: 0.1436, r_value: 0.4854
Epoch 3000, train_loss: 0.1425, val_loss: 0.1429, r_value: 0.4906
Epoch 3500, train_loss: 0.1412, val_loss: 0.1422, r_value: 0.4945
Epoch 4000, train_loss: 0.1405, val_loss: 0.1433, r_value: 0.5006
Epoch 4500, train_loss: 0.1381, val_loss: 0.1422, r_value: 0.5001
Epoch 5000, train_loss: 0.1386, val_loss: 0.1399, r_value: 0.5054
Epoch 5500, train_loss: 0.1363, val_loss: 0.1379, r_value: 0.5029
Epoch 6000, train_loss: 0.1365, val_loss: 0.1391, r_value: 0.5123
Epoch 6500, train_loss: 0.1362, val_loss: 0.1385, r_value: 0.5140
Epoch 7000, train_loss: 0.1363, val_loss: 0.1396, r_value: 0.5150
Epoch 7500, train_loss: 0.1384, val_loss: 0.1431, r_value: 0.4806
Epoch 8000, train_loss: 0.1330, val_loss: 0.1358, r_value: 0.5150
Epoch 8500, train_loss: 0.1386, val_loss: 0.1397, r_value: 0.5157
Epoch 9000, train_loss: 0.1329, val_loss: 0.1355, r_value: 0.5169
Epoch 9500, train_loss: 0.1343, val_loss: 0.1383, r_value: 0.5205
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_17_3.png" src="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_17_3.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

hid_dim: 128, lr: 0.1
Deleting previous model
Epoch 0, train_loss: 0.1972, val_loss: 0.1922, r_value: -0.0228
Epoch 500, train_loss: 0.1475, val_loss: 0.1487, r_value: 0.4403
Epoch 1000, train_loss: 0.1456, val_loss: 0.1468, r_value: 0.4565
Epoch 1500, train_loss: 0.1445, val_loss: 0.1457, r_value: 0.4629
Epoch 2000, train_loss: 0.1436, val_loss: 0.1448, r_value: 0.4672
Epoch 2500, train_loss: 0.1430, val_loss: 0.1442, r_value: 0.4711
Epoch 3000, train_loss: 0.1424, val_loss: 0.1436, r_value: 0.4747
Epoch 3500, train_loss: 0.1418, val_loss: 0.1430, r_value: 0.4781
Epoch 4000, train_loss: 0.1412, val_loss: 0.1425, r_value: 0.4814
Epoch 4500, train_loss: 0.1407, val_loss: 0.1420, r_value: 0.4845
Epoch 5000, train_loss: 0.1402, val_loss: 0.1415, r_value: 0.4874
Epoch 5500, train_loss: 0.1396, val_loss: 0.1410, r_value: 0.4901
Epoch 6000, train_loss: 0.1391, val_loss: 0.1405, r_value: 0.4926
Epoch 6500, train_loss: 0.1387, val_loss: 0.1402, r_value: 0.4949
Epoch 7000, train_loss: 0.1383, val_loss: 0.1398, r_value: 0.4972
Epoch 7500, train_loss: 0.1379, val_loss: 0.1394, r_value: 0.4994
Epoch 8000, train_loss: 0.1374, val_loss: 0.1391, r_value: 0.5016
Epoch 8500, train_loss: 0.1370, val_loss: 0.1387, r_value: 0.5038
Epoch 9000, train_loss: 0.1366, val_loss: 0.1385, r_value: 0.5059
Epoch 9500, train_loss: 0.1361, val_loss: 0.1380, r_value: 0.5078
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_17_5.png" src="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_17_5.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

hid_dim: 128, lr: 0.01
Deleting previous model
Epoch 0, train_loss: 0.1834, val_loss: 0.1853, r_value: -0.2359
Epoch 500, train_loss: 0.1816, val_loss: 0.1834, r_value: 0.3388
Epoch 1000, train_loss: 0.1804, val_loss: 0.1822, r_value: 0.3865
Epoch 1500, train_loss: 0.1786, val_loss: 0.1804, r_value: 0.4007
Epoch 2000, train_loss: 0.1755, val_loss: 0.1772, r_value: 0.4089
Epoch 2500, train_loss: 0.1692, val_loss: 0.1710, r_value: 0.4173
Epoch 3000, train_loss: 0.1597, val_loss: 0.1614, r_value: 0.4241
Epoch 3500, train_loss: 0.1513, val_loss: 0.1530, r_value: 0.4315
Epoch 4000, train_loss: 0.1479, val_loss: 0.1495, r_value: 0.4389
Epoch 4500, train_loss: 0.1467, val_loss: 0.1482, r_value: 0.4441
Epoch 5000, train_loss: 0.1461, val_loss: 0.1475, r_value: 0.4475
Epoch 5500, train_loss: 0.1457, val_loss: 0.1471, r_value: 0.4498
Epoch 6000, train_loss: 0.1454, val_loss: 0.1468, r_value: 0.4516
Epoch 6500, train_loss: 0.1452, val_loss: 0.1465, r_value: 0.4530
Epoch 7000, train_loss: 0.1450, val_loss: 0.1463, r_value: 0.4542
Epoch 7500, train_loss: 0.1448, val_loss: 0.1462, r_value: 0.4553
Epoch 8000, train_loss: 0.1447, val_loss: 0.1460, r_value: 0.4562
Epoch 8500, train_loss: 0.1445, val_loss: 0.1459, r_value: 0.4570
Epoch 9000, train_loss: 0.1444, val_loss: 0.1457, r_value: 0.4579
Epoch 9500, train_loss: 0.1443, val_loss: 0.1456, r_value: 0.4587
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_17_7.png" src="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_17_7.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

hid_dim: 128, lr: 0.05
Deleting previous model
Epoch 0, train_loss: 0.1844, val_loss: 0.1855, r_value: -0.0339
Epoch 500, train_loss: 0.1709, val_loss: 0.1725, r_value: 0.4039
Epoch 1000, train_loss: 0.1479, val_loss: 0.1493, r_value: 0.4363
Epoch 1500, train_loss: 0.1458, val_loss: 0.1472, r_value: 0.4492
Epoch 2000, train_loss: 0.1446, val_loss: 0.1460, r_value: 0.4565
Epoch 2500, train_loss: 0.1437, val_loss: 0.1451, r_value: 0.4617
Epoch 3000, train_loss: 0.1431, val_loss: 0.1444, r_value: 0.4655
Epoch 3500, train_loss: 0.1425, val_loss: 0.1439, r_value: 0.4688
Epoch 4000, train_loss: 0.1419, val_loss: 0.1434, r_value: 0.4717
Epoch 4500, train_loss: 0.1414, val_loss: 0.1429, r_value: 0.4745
Epoch 5000, train_loss: 0.1409, val_loss: 0.1423, r_value: 0.4776
Epoch 5500, train_loss: 0.1411, val_loss: 0.1423, r_value: 0.4798
Epoch 6000, train_loss: 0.1408, val_loss: 0.1420, r_value: 0.4822
Epoch 6500, train_loss: 0.1404, val_loss: 0.1417, r_value: 0.4844
Epoch 7000, train_loss: 0.1401, val_loss: 0.1414, r_value: 0.4864
Epoch 7500, train_loss: 0.1398, val_loss: 0.1411, r_value: 0.4883
Epoch 8000, train_loss: 0.1395, val_loss: 0.1408, r_value: 0.4901
Epoch 8500, train_loss: 0.1392, val_loss: 0.1405, r_value: 0.4920
Epoch 9000, train_loss: 0.1389, val_loss: 0.1402, r_value: 0.4937
Epoch 9500, train_loss: 0.1386, val_loss: 0.1399, r_value: 0.4954
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_17_9.png" src="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_17_9.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

hid_dim: 256, lr: 0.75
Deleting previous model
Epoch 0, train_loss: 0.1854, val_loss: 0.1890, r_value: -0.2486
Epoch 500, train_loss: 0.1587, val_loss: 0.1572, r_value: 0.4538
Epoch 1000, train_loss: 0.1548, val_loss: 0.1555, r_value: 0.4659
Epoch 1500, train_loss: 0.1518, val_loss: 0.1534, r_value: 0.4754
Epoch 2000, train_loss: 0.1495, val_loss: 0.1514, r_value: 0.4823
Epoch 2500, train_loss: 0.1474, val_loss: 0.1491, r_value: 0.4899
Epoch 3000, train_loss: 0.1412, val_loss: 0.1421, r_value: 0.4947
Epoch 3500, train_loss: 0.1550, val_loss: 0.1552, r_value: 0.4857
Epoch 4000, train_loss: 0.1420, val_loss: 0.1473, r_value: 0.4894
Epoch 4500, train_loss: 0.1353, val_loss: 0.1378, r_value: 0.5060
Epoch 5000, train_loss: 0.1425, val_loss: 0.1447, r_value: 0.5064
Epoch 5500, train_loss: 0.1410, val_loss: 0.1450, r_value: 0.5103
Epoch 6000, train_loss: 0.1360, val_loss: 0.1388, r_value: 0.5132
Epoch 6500, train_loss: 0.1369, val_loss: 0.1373, r_value: 0.5113
Epoch 7000, train_loss: 0.1404, val_loss: 0.1436, r_value: 0.5155
Epoch 7500, train_loss: 0.1334, val_loss: 0.1366, r_value: 0.5119
Epoch 8000, train_loss: 0.1375, val_loss: 0.1412, r_value: 0.5187
Epoch 8500, train_loss: 0.1330, val_loss: 0.1361, r_value: 0.5206
Epoch 9000, train_loss: 0.1390, val_loss: 0.1421, r_value: 0.5209
Epoch 9500, train_loss: 0.1322, val_loss: 0.1358, r_value: 0.5167
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_17_11.png" src="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_17_11.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

hid_dim: 256, lr: 0.5
Deleting previous model
Epoch 0, train_loss: 0.1823, val_loss: 0.1839, r_value: 0.2372
Epoch 500, train_loss: 0.1497, val_loss: 0.1501, r_value: 0.4585
Epoch 1000, train_loss: 0.1461, val_loss: 0.1475, r_value: 0.4726
Epoch 1500, train_loss: 0.1438, val_loss: 0.1456, r_value: 0.4814
Epoch 2000, train_loss: 0.1425, val_loss: 0.1444, r_value: 0.4886
Epoch 2500, train_loss: 0.1411, val_loss: 0.1432, r_value: 0.4963
Epoch 3000, train_loss: 0.1396, val_loss: 0.1414, r_value: 0.5006
Epoch 3500, train_loss: 0.1413, val_loss: 0.1433, r_value: 0.5074
Epoch 4000, train_loss: 0.1374, val_loss: 0.1397, r_value: 0.5112
Epoch 4500, train_loss: 0.1379, val_loss: 0.1402, r_value: 0.5129
Epoch 5000, train_loss: 0.1371, val_loss: 0.1393, r_value: 0.5124
Epoch 5500, train_loss: 0.1339, val_loss: 0.1369, r_value: 0.5089
Epoch 6000, train_loss: 0.1360, val_loss: 0.1388, r_value: 0.5179
Epoch 6500, train_loss: 0.1366, val_loss: 0.1397, r_value: 0.5188
Epoch 7000, train_loss: 0.1368, val_loss: 0.1391, r_value: 0.5199
Epoch 7500, train_loss: 0.1350, val_loss: 0.1386, r_value: 0.5212
Epoch 8000, train_loss: 0.1351, val_loss: 0.1384, r_value: 0.5192
Epoch 8500, train_loss: 0.1331, val_loss: 0.1372, r_value: 0.5095
Epoch 9000, train_loss: 0.1336, val_loss: 0.1376, r_value: 0.5201
Epoch 9500, train_loss: 0.1310, val_loss: 0.1350, r_value: 0.5212
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_17_13.png" src="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_17_13.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

hid_dim: 256, lr: 0.1
Deleting previous model
Epoch 0, train_loss: 0.1824, val_loss: 0.1841, r_value: 0.1137
Epoch 500, train_loss: 0.1458, val_loss: 0.1472, r_value: 0.4493
Epoch 1000, train_loss: 0.1450, val_loss: 0.1465, r_value: 0.4604
Epoch 1500, train_loss: 0.1440, val_loss: 0.1455, r_value: 0.4666
Epoch 2000, train_loss: 0.1432, val_loss: 0.1447, r_value: 0.4715
Epoch 2500, train_loss: 0.1423, val_loss: 0.1439, r_value: 0.4762
Epoch 3000, train_loss: 0.1416, val_loss: 0.1432, r_value: 0.4807
Epoch 3500, train_loss: 0.1409, val_loss: 0.1425, r_value: 0.4852
Epoch 4000, train_loss: 0.1402, val_loss: 0.1419, r_value: 0.4893
Epoch 4500, train_loss: 0.1395, val_loss: 0.1413, r_value: 0.4932
Epoch 5000, train_loss: 0.1389, val_loss: 0.1407, r_value: 0.4967
Epoch 5500, train_loss: 0.1383, val_loss: 0.1402, r_value: 0.4999
Epoch 6000, train_loss: 0.1376, val_loss: 0.1396, r_value: 0.5028
Epoch 6500, train_loss: 0.1370, val_loss: 0.1391, r_value: 0.5055
Epoch 7000, train_loss: 0.1365, val_loss: 0.1387, r_value: 0.5080
Epoch 7500, train_loss: 0.1360, val_loss: 0.1383, r_value: 0.5102
Epoch 8000, train_loss: 0.1354, val_loss: 0.1378, r_value: 0.5122
Epoch 8500, train_loss: 0.1350, val_loss: 0.1375, r_value: 0.5138
Epoch 9000, train_loss: 0.1346, val_loss: 0.1372, r_value: 0.5152
Epoch 9500, train_loss: 0.1343, val_loss: 0.1369, r_value: 0.5165
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_17_15.png" src="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_17_15.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

hid_dim: 256, lr: 0.01
Deleting previous model
Epoch 0, train_loss: 0.1834, val_loss: 0.1850, r_value: -0.2138
Epoch 500, train_loss: 0.1808, val_loss: 0.1825, r_value: 0.4074
Epoch 1000, train_loss: 0.1779, val_loss: 0.1797, r_value: 0.4218
Epoch 1500, train_loss: 0.1725, val_loss: 0.1742, r_value: 0.4248
Epoch 2000, train_loss: 0.1624, val_loss: 0.1640, r_value: 0.4276
Epoch 2500, train_loss: 0.1521, val_loss: 0.1536, r_value: 0.4321
Epoch 3000, train_loss: 0.1481, val_loss: 0.1495, r_value: 0.4383
Epoch 3500, train_loss: 0.1469, val_loss: 0.1483, r_value: 0.4432
Epoch 4000, train_loss: 0.1463, val_loss: 0.1477, r_value: 0.4465
Epoch 4500, train_loss: 0.1459, val_loss: 0.1472, r_value: 0.4488
Epoch 5000, train_loss: 0.1456, val_loss: 0.1469, r_value: 0.4507
Epoch 5500, train_loss: 0.1453, val_loss: 0.1467, r_value: 0.4524
Epoch 6000, train_loss: 0.1451, val_loss: 0.1464, r_value: 0.4538
Epoch 6500, train_loss: 0.1448, val_loss: 0.1462, r_value: 0.4551
Epoch 7000, train_loss: 0.1447, val_loss: 0.1460, r_value: 0.4562
Epoch 7500, train_loss: 0.1445, val_loss: 0.1458, r_value: 0.4572
Epoch 8000, train_loss: 0.1443, val_loss: 0.1457, r_value: 0.4582
Epoch 8500, train_loss: 0.1442, val_loss: 0.1455, r_value: 0.4591
Epoch 9000, train_loss: 0.1440, val_loss: 0.1454, r_value: 0.4599
Epoch 9500, train_loss: 0.1439, val_loss: 0.1453, r_value: 0.4606
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_17_17.png" src="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_17_17.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

hid_dim: 256, lr: 0.05
Deleting previous model
Epoch 0, train_loss: 0.1841, val_loss: 0.1851, r_value: 0.1820
Epoch 500, train_loss: 0.1507, val_loss: 0.1521, r_value: 0.4349
Epoch 1000, train_loss: 0.1456, val_loss: 0.1469, r_value: 0.4511
Epoch 1500, train_loss: 0.1443, val_loss: 0.1456, r_value: 0.4585
Epoch 2000, train_loss: 0.1435, val_loss: 0.1448, r_value: 0.4635
Epoch 2500, train_loss: 0.1428, val_loss: 0.1441, r_value: 0.4673
Epoch 3000, train_loss: 0.1422, val_loss: 0.1435, r_value: 0.4707
Epoch 3500, train_loss: 0.1416, val_loss: 0.1430, r_value: 0.4738
Epoch 4000, train_loss: 0.1416, val_loss: 0.1428, r_value: 0.4765
Epoch 4500, train_loss: 0.1413, val_loss: 0.1426, r_value: 0.4790
Epoch 5000, train_loss: 0.1409, val_loss: 0.1422, r_value: 0.4814
Epoch 5500, train_loss: 0.1406, val_loss: 0.1419, r_value: 0.4837
Epoch 6000, train_loss: 0.1401, val_loss: 0.1415, r_value: 0.4858
Epoch 6500, train_loss: 0.1398, val_loss: 0.1411, r_value: 0.4880
Epoch 7000, train_loss: 0.1394, val_loss: 0.1408, r_value: 0.4901
Epoch 7500, train_loss: 0.1390, val_loss: 0.1405, r_value: 0.4921
Epoch 8000, train_loss: 0.1387, val_loss: 0.1402, r_value: 0.4940
Epoch 8500, train_loss: 0.1383, val_loss: 0.1398, r_value: 0.4957
Epoch 9000, train_loss: 0.1380, val_loss: 0.1395, r_value: 0.4975
Epoch 9500, train_loss: 0.1376, val_loss: 0.1392, r_value: 0.4992
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_17_19.png" src="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_17_19.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

hid_dim: 512, lr: 0.75
Deleting previous model
Epoch 0, train_loss: 0.1826, val_loss: 0.1840, r_value: 0.3779
Epoch 500, train_loss: 0.1557, val_loss: 0.1588, r_value: 0.4407
Epoch 1000, train_loss: 0.1528, val_loss: 0.1545, r_value: 0.4622
Epoch 1500, train_loss: 0.1502, val_loss: 0.1516, r_value: 0.4754
Epoch 2000, train_loss: 0.1483, val_loss: 0.1501, r_value: 0.4830
Epoch 2500, train_loss: 0.1478, val_loss: 0.1489, r_value: 0.4910
Epoch 3000, train_loss: 0.1453, val_loss: 0.1469, r_value: 0.4976
Epoch 3500, train_loss: 0.1421, val_loss: 0.1462, r_value: 0.4990
Epoch 4000, train_loss: 0.1363, val_loss: 0.1382, r_value: 0.5105
Epoch 4500, train_loss: 0.1368, val_loss: 0.1406, r_value: 0.5128
Epoch 5000, train_loss: 0.1421, val_loss: 0.1482, r_value: 0.4841
Epoch 5500, train_loss: 0.1372, val_loss: 0.1428, r_value: 0.5116
Epoch 6000, train_loss: 0.1416, val_loss: 0.1464, r_value: 0.5134
Epoch 6500, train_loss: 0.1405, val_loss: 0.1478, r_value: 0.4916
Epoch 7000, train_loss: 0.1385, val_loss: 0.1445, r_value: 0.5168
Epoch 7500, train_loss: 0.1318, val_loss: 0.1365, r_value: 0.5228
Epoch 8000, train_loss: 0.1436, val_loss: 0.1462, r_value: 0.5013
Epoch 8500, train_loss: 0.1391, val_loss: 0.1479, r_value: 0.5128
Epoch 9000, train_loss: 0.1300, val_loss: 0.1364, r_value: 0.5165
Epoch 9500, train_loss: 0.1299, val_loss: 0.1350, r_value: 0.5266
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_17_21.png" src="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_17_21.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

hid_dim: 512, lr: 0.5
Deleting previous model
Epoch 0, train_loss: 0.1835, val_loss: 0.1845, r_value: 0.0661
Epoch 500, train_loss: 0.1480, val_loss: 0.1502, r_value: 0.4544
Epoch 1000, train_loss: 0.1449, val_loss: 0.1460, r_value: 0.4766
Epoch 1500, train_loss: 0.1425, val_loss: 0.1434, r_value: 0.4885
Epoch 2000, train_loss: 0.1417, val_loss: 0.1423, r_value: 0.4973
Epoch 2500, train_loss: 0.1392, val_loss: 0.1408, r_value: 0.5002
Epoch 3000, train_loss: 0.1384, val_loss: 0.1402, r_value: 0.5085
Epoch 3500, train_loss: 0.1363, val_loss: 0.1385, r_value: 0.5105
Epoch 4000, train_loss: 0.1372, val_loss: 0.1397, r_value: 0.5167
Epoch 4500, train_loss: 0.1359, val_loss: 0.1386, r_value: 0.5166
Epoch 5000, train_loss: 0.1355, val_loss: 0.1386, r_value: 0.5206
Epoch 5500, train_loss: 0.1326, val_loss: 0.1350, r_value: 0.5214
Epoch 6000, train_loss: 0.1313, val_loss: 0.1345, r_value: 0.5222
Epoch 6500, train_loss: 0.1336, val_loss: 0.1378, r_value: 0.5250
Epoch 7000, train_loss: 0.1341, val_loss: 0.1378, r_value: 0.5228
Epoch 7500, train_loss: 0.1337, val_loss: 0.1389, r_value: 0.5230
Epoch 8000, train_loss: 0.1327, val_loss: 0.1393, r_value: 0.5248
Epoch 8500, train_loss: 0.1309, val_loss: 0.1365, r_value: 0.5216
Epoch 9000, train_loss: 0.1315, val_loss: 0.1368, r_value: 0.5292
Epoch 9500, train_loss: 0.1314, val_loss: 0.1367, r_value: 0.5274
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_17_23.png" src="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_17_23.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

hid_dim: 512, lr: 0.1
Deleting previous model
Epoch 0, train_loss: 0.1826, val_loss: 0.1842, r_value: 0.0892
Epoch 500, train_loss: 0.1468, val_loss: 0.1481, r_value: 0.4540
Epoch 1000, train_loss: 0.1445, val_loss: 0.1459, r_value: 0.4648
Epoch 1500, train_loss: 0.1431, val_loss: 0.1446, r_value: 0.4718
Epoch 2000, train_loss: 0.1421, val_loss: 0.1436, r_value: 0.4778
Epoch 2500, train_loss: 0.1411, val_loss: 0.1427, r_value: 0.4831
Epoch 3000, train_loss: 0.1403, val_loss: 0.1420, r_value: 0.4877
Epoch 3500, train_loss: 0.1396, val_loss: 0.1413, r_value: 0.4918
Epoch 4000, train_loss: 0.1389, val_loss: 0.1407, r_value: 0.4957
Epoch 4500, train_loss: 0.1382, val_loss: 0.1401, r_value: 0.4995
Epoch 5000, train_loss: 0.1375, val_loss: 0.1395, r_value: 0.5032
Epoch 5500, train_loss: 0.1369, val_loss: 0.1390, r_value: 0.5067
Epoch 6000, train_loss: 0.1362, val_loss: 0.1384, r_value: 0.5097
Epoch 6500, train_loss: 0.1356, val_loss: 0.1379, r_value: 0.5124
Epoch 7000, train_loss: 0.1350, val_loss: 0.1375, r_value: 0.5146
Epoch 7500, train_loss: 0.1345, val_loss: 0.1371, r_value: 0.5164
Epoch 8000, train_loss: 0.1341, val_loss: 0.1368, r_value: 0.5179
Epoch 8500, train_loss: 0.1337, val_loss: 0.1365, r_value: 0.5191
Epoch 9000, train_loss: 0.1333, val_loss: 0.1363, r_value: 0.5202
Epoch 9500, train_loss: 0.1329, val_loss: 0.1360, r_value: 0.5212
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_17_25.png" src="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_17_25.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

hid_dim: 512, lr: 0.01
Deleting previous model
Epoch 0, train_loss: 0.1827, val_loss: 0.1845, r_value: -0.0949
Epoch 500, train_loss: 0.1791, val_loss: 0.1809, r_value: 0.4072
Epoch 1000, train_loss: 0.1732, val_loss: 0.1749, r_value: 0.4166
Epoch 1500, train_loss: 0.1618, val_loss: 0.1634, r_value: 0.4232
Epoch 2000, train_loss: 0.1512, val_loss: 0.1527, r_value: 0.4312
Epoch 2500, train_loss: 0.1477, val_loss: 0.1492, r_value: 0.4393
Epoch 3000, train_loss: 0.1466, val_loss: 0.1480, r_value: 0.4447
Epoch 3500, train_loss: 0.1460, val_loss: 0.1473, r_value: 0.4484
Epoch 4000, train_loss: 0.1455, val_loss: 0.1469, r_value: 0.4512
Epoch 4500, train_loss: 0.1451, val_loss: 0.1465, r_value: 0.4535
Epoch 5000, train_loss: 0.1448, val_loss: 0.1461, r_value: 0.4555
Epoch 5500, train_loss: 0.1445, val_loss: 0.1458, r_value: 0.4573
Epoch 6000, train_loss: 0.1442, val_loss: 0.1456, r_value: 0.4589
Epoch 6500, train_loss: 0.1440, val_loss: 0.1453, r_value: 0.4603
Epoch 7000, train_loss: 0.1438, val_loss: 0.1451, r_value: 0.4616
Epoch 7500, train_loss: 0.1436, val_loss: 0.1449, r_value: 0.4627
Epoch 8000, train_loss: 0.1434, val_loss: 0.1447, r_value: 0.4638
Epoch 8500, train_loss: 0.1433, val_loss: 0.1446, r_value: 0.4647
Epoch 9000, train_loss: 0.1431, val_loss: 0.1444, r_value: 0.4656
Epoch 9500, train_loss: 0.1430, val_loss: 0.1443, r_value: 0.4664
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_17_27.png" src="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_17_27.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

hid_dim: 512, lr: 0.05
Deleting previous model
Epoch 0, train_loss: 0.1837, val_loss: 0.1852, r_value: 0.0732
Epoch 500, train_loss: 0.1470, val_loss: 0.1484, r_value: 0.4426
Epoch 1000, train_loss: 0.1447, val_loss: 0.1461, r_value: 0.4556
Epoch 1500, train_loss: 0.1437, val_loss: 0.1451, r_value: 0.4617
Epoch 2000, train_loss: 0.1430, val_loss: 0.1444, r_value: 0.4658
Epoch 2500, train_loss: 0.1424, val_loss: 0.1438, r_value: 0.4694
Epoch 3000, train_loss: 0.1423, val_loss: 0.1436, r_value: 0.4724
Epoch 3500, train_loss: 0.1419, val_loss: 0.1431, r_value: 0.4755
Epoch 4000, train_loss: 0.1414, val_loss: 0.1427, r_value: 0.4786
Epoch 4500, train_loss: 0.1409, val_loss: 0.1422, r_value: 0.4815
Epoch 5000, train_loss: 0.1404, val_loss: 0.1418, r_value: 0.4844
Epoch 5500, train_loss: 0.1399, val_loss: 0.1413, r_value: 0.4873
Epoch 6000, train_loss: 0.1394, val_loss: 0.1408, r_value: 0.4901
Epoch 6500, train_loss: 0.1390, val_loss: 0.1404, r_value: 0.4927
Epoch 7000, train_loss: 0.1385, val_loss: 0.1399, r_value: 0.4953
Epoch 7500, train_loss: 0.1380, val_loss: 0.1395, r_value: 0.4976
Epoch 8000, train_loss: 0.1376, val_loss: 0.1391, r_value: 0.4999
Epoch 8500, train_loss: 0.1371, val_loss: 0.1388, r_value: 0.5021
Epoch 9000, train_loss: 0.1367, val_loss: 0.1384, r_value: 0.5041
Epoch 9500, train_loss: 0.1362, val_loss: 0.1380, r_value: 0.5060
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_17_29.png" src="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_17_29.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Let&#39;s try the sklearn MLP implementation</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.neural_network</span><span class="w"> </span><span class="kn">import</span> <span class="n">MLPRegressor</span>
<span class="n">regr</span> <span class="o">=</span> <span class="n">MLPRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">regr</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
MLPRegressor(max_iter=1000, random_state=1)
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">regr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">slope</span><span class="p">,</span> <span class="n">intercept</span><span class="p">,</span> <span class="n">r_value</span><span class="p">,</span> <span class="n">p_value</span><span class="p">,</span> <span class="n">std_err</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">linregress</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_test</span><span class="o">.</span><span class="n">cpu</span><span class="p">())</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Prediction&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;True&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;slope: </span><span class="si">{:.4f}</span><span class="s1">, r_value: </span><span class="si">{:.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">slope</span><span class="p">,</span> <span class="n">r_value</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Text(0.5, 1.0, &#39;slope: 0.9208, r_value: 0.5133&#39;)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_19_1.png" src="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_19_1.png" />
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">regr</span> <span class="o">=</span> <span class="n">MLPRegressor</span><span class="p">(</span><span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span><span class="mi">256</span><span class="p">,</span><span class="mi">256</span><span class="p">),</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">regr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">slope</span><span class="p">,</span> <span class="n">intercept</span><span class="p">,</span> <span class="n">r_value</span><span class="p">,</span> <span class="n">p_value</span><span class="p">,</span> <span class="n">std_err</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">linregress</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_test</span><span class="o">.</span><span class="n">cpu</span><span class="p">())</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Prediction&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;True&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;slope: </span><span class="si">{:.4f}</span><span class="s1">, r_value: </span><span class="si">{:.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">slope</span><span class="p">,</span> <span class="n">r_value</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Text(0.5, 1.0, &#39;slope: 0.3976, r_value: 0.3469&#39;)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_21_1.png" src="../_images/CASESTUDY_Tree_Height_07FeedForward_Networks_2024_21_1.png" />
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="Tree_Height_06NeuralNets_pred.html" class="btn btn-neutral float-left" title="Estimation of tree height using GEDI dataset - Neural Network 1" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="NNs_pt3_SHAP.html" class="btn btn-neutral float-right" title="Neural Nets (pt.3), Interpretability and Convolutional Neural Networks" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, Giuseppe Amatulli.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>