<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>2.7. Yusdiel Torres-Cambas: Distribution of freshwater biodiversity across Cuba &mdash; Spatial Ecology&#39;s code documentation 0.0.1 documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/jupyter-sphinx.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/thebelab.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/thebelab-helper.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="2.8. Txomin Bornaetxea: Modeling debris flow source areas" href="Modeling_debris_flow_source_areas_Txomin_Bornaetxea.html" />
    <link rel="prev" title="2.5. Afroditi Grigoropoulou: Species Distribution Model with Random Forest" href="Species_Distribution_Model_with_Random_Forest_Afroditi_Grigoropoulou.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> Spatial Ecology's code documentation
            <img src="../../_static/SE_compact.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">COURSE TRAINERS</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../COURSETRAINERS/trainers.html">Spatial Ecology course trainers</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">COURSES AROUND THE WORLD</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../COURSESAROUNDTHEWORLD/course_wcsu_02-04_2021.html">Western Connecticut State University 2021</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../COURSESAROUNDTHEWORLD/course_stock_uni_04-05_2021.html">Stockholm University 2021</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../COURSESAROUNDTHEWORLD/course_geocomp_ml_04-05_2022.html">GeoComp &amp; ML 2022 course</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">GEO DATA</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../GEODATA/geomorpho90m/geomorpho90m.html">Geomorpho90m: technical documentation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">LINUX VIRTUAL MACHINE</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../VIRTUALMACHINE/Setting_Colab_for_for_Spatial_Ecology_course.html">Prepare Colab for Spatial Ecology courses</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../VIRTUALMACHINE/Setting_OSGeoLive_for_for_Spatial_Ecology_course.html">Prepare OSGeoLive for Spatial Ecology courses</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../VIRTUALMACHINE/Setting_OSGeoLive_curso_para_Ecologia_Espacial.html">Prepare OSGeoLive para el curso de ecología espacial</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">WEB SEMINARS</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../WEBSEMINAR/webseminar.html">Raster/Vector Processing using GDAL/OGR</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../WEBSEMINAR/webseminar.html#image-processing-using-pktools">Image Processing using Pktools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../WEBSEMINAR/webseminar.html#introduction-to-grass-gis">Introduction to GRASS GIS</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../WEBSEMINAR/webseminar.html#geocomputation-with-high-performance-computing">GeoComputation with High Performance Computing</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">BASH</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../BASH/bashintro_osgeo.html">Linux Operation System as a base for Spatial Ecology Computing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../BASH/bashinter_osgeo.html">Manipulate text files in bash</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../BASH/bashxargs_osgeo.html">Multi-core bash</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">AWK</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../AWK/awk.html">AWK Tutorial</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">GDAL</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../GDAL/gdal_osgeo.html">Use GDAL/OGR for raster/vector operations - osgeo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../GDAL/gdal_colab.html">Use GDAL/OGR for raster/vector operations - colab</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">PKTOOLS</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../PKTOOLS/pktools_osgeo.html">Use PKTOOLS for raster/vector operations - osgeo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../PKTOOLS/pktools_colab.html">Use PKTOOLS for raster/vector operations - colab</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../PKTOOLS/pyjeo_introduction.html">Introdction to pyjeo: installation and raster visualization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../PKTOOLS/pyjeo_pktools.html">Performing raster and vector operations in Python using pyjeo</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">R</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../R/R_Intro.html">R Introduction</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">PYTHON</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../PYTHON/Python_Intro.html">Introduction to Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../PYTHON/Geo_Python.html">Python &amp; GeoComputation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">GRASS</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../GRASS/grass_intro.html">GRASS Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../GRASS/grass_hydro.html">Using GRASS for stream-network extraction and basins delineation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">CASE STUDY</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../CASESTUDY/SDM1_MWood_gecomp.html">SDM1 : Montane woodcreper - Gecomputation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../CASESTUDY/SDM1_MWood_Rmodel.html">SDM1 : Montane woodcreper - Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../CASESTUDY/SDM2_Vath_Rmodel.html">SDM2 : Varied Thrush - Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../CASESTUDY/manipulate_GSIM.html">Manipulate GSIM files</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../CASESTUDY/Data_type_GTiff.html">Data type in GTiff</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../CASESTUDY/temporal_interpolation.html">Temporal interpolation of landsat images</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../CASESTUDY/DTW.html">Dynamic Time Warping</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../CASESTUDY/pred_NP.html">Estimating nitrogen and phosphorus concentrations in streams and rivers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../CASESTUDY/NN-day1.html">Estimating nitrogen concentrations in streams and rivers using NN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../CASESTUDY/NN-day2.html">Autoencoder (AE), Variational Autoencoder (VAE) and Generative Adversarial Network (GAN)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../CASESTUDY/NN-day3.html">LSTM Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../CASESTUDY/Tree_Height_01DataExplore.html">Estimation of tree height using GEDI dataset - Data explore</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../CASESTUDY/Tree_Height_02SVM_pred.html">Estimation of tree height using GEDI dataset - Support Vector Machine for Regression (SVR)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../CASESTUDY/Tree_Height_03RF_pred.html">Estimation of tree height using GEDI dataset - Random Forest prediction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../CASESTUDY/Tree_Height_04Perceptron_pred.html">Estimation of tree height using GEDI dataset - Perceptron 1</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../CASESTUDY/Tree_Height_04Perceptron_pred_clean.html">Estimation of tree height using GEDI dataset - Clean Data - Perceptron 2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../CASESTUDY/Tree_Height_05NeuralNets_pred.html">Estimation of tree height using GEDI dataset - Neural Network 1</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../CASESTUDY/NNs_pt3_SHAP.html">Neural Nets (pt.3), Interpretability and Convolutional Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../CASESTUDY/CNN_satelite.html">Using Multi-layer Perceptron and Convolutional Neural Networks for Satellite image classification.</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../CASESTUDY/LSTMs_tutorial.html">The real data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../CASESTUDY/LSTMs_tutorial.html#LSTM-for-Regression-Using-the-Window-Method">LSTM for Regression Using the Window Method</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../CASESTUDY/LSTMs_tutorial.html#LSTM-for-Regression-with-Time-Steps">LSTM for Regression with Time Steps</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../CASESTUDY/LSTMs_tutorial.html#LSTM-with-Memory-Between-Batches">LSTM with Memory Between Batches</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../CASESTUDY/LSTMs_tutorial.html#Stacked-LSTMs-with-Memory-Between-Batches">Stacked LSTMs with Memory Between Batches</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../CASESTUDY/LSTMs_tutorial.html#Adding-Early-Stopping">Adding Early Stopping</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../CASESTUDY/LSTMs_tutorial.html#Multivariate-Time-series---Data">Multivariate Time-series - Data</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Students Projects</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../index.html">1. 2021 SWEDEN</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html#matera">2. 2022 MATERA</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="Damaged_trees_classification_RF_Janusz_Godziek.html">2.1. Janusz Godziek: Damaged vs undamaged trees - Random Forest classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="Stream_Network_Abstraction_Alonso_Gonzalez.html">2.2. Alonso Gonzalez: Stream Network Abstraction</a></li>
<li class="toctree-l2"><a class="reference internal" href="Images_shadow_removal_Sebastian_Walter.html">2.3. Sebastian Walter: Images shadow removal</a></li>
<li class="toctree-l2"><a class="reference internal" href="Using_a_LSTM_network_and_SHAP_to_determine_the_impact_of_drought_Florian_Ells%C3%A4%C3%9Fer.html">2.4. Florian Ellsäßer: Using a LSTM network and SHAP to determine the impact of drought and season on winter wheat</a></li>
<li class="toctree-l2"><a class="reference internal" href="Species_Distribution_Model_with_Random_Forest_Afroditi_Grigoropoulou.html">2.5. Afroditi Grigoropoulou: Species Distribution Model with Random Forest</a></li>
<li class="toctree-l2"><a class="reference internal" href="Species_Distribution_Model_with_Random_Forest_Afroditi_Grigoropoulou.html#random-forest-classification">2.6. Random forest classification</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">2.7. Yusdiel Torres-Cambas: Distribution of freshwater biodiversity across Cuba</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#introduction">2.7.1. Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="#predictor-variables">2.7.2. 1. Predictor variables</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#download-and-mosaic-tiles-of-a-digital-elevation-model">2.7.2.1. 1.1. Download and mosaic tiles of a digital elevation model</a></li>
<li class="toctree-l4"><a class="reference internal" href="#download-bioclimatic-variables">2.7.2.2. 1.2. Download bioclimatic variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="#download-and-mosaic-tiles-of-tree-cover">2.7.2.3. 1.3. Download and mosaic tiles of tree cover</a></li>
<li class="toctree-l4"><a class="reference internal" href="#calculate-slope">2.7.2.4. 1.4. Calculate slope</a></li>
<li class="toctree-l4"><a class="reference internal" href="#crop-and-reproject">2.7.2.5. 1.5. Crop and reproject</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#stream-network-and-sub-basins">2.7.3. 2. Stream network and sub-basins</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#make-a-grass-gis-database">2.7.3.1. 2.1. Make a GRASS GIS database</a></li>
<li class="toctree-l4"><a class="reference internal" href="#extract-flow-direction-flow-accumulation-stream-network-basins-and-sub-basins">2.7.3.2. 2.2. Extract flow direction, flow accumulation, stream network, basins and sub-basins</a></li>
<li class="toctree-l4"><a class="reference internal" href="#aggregate-predictors-by-sub-basin">2.7.3.3. 2.3. Aggregate predictors by sub-basin</a></li>
<li class="toctree-l4"><a class="reference internal" href="#make-maps-with-presence-and-pseudoabsences">2.7.3.4. 3.2. Make maps with presence and pseudoabsences</a></li>
<li class="toctree-l4"><a class="reference internal" href="#make-inputs-required-to-create-an-ssn-object-a-kind-of-r-object-necessary-to-fit-a-spatial-linear-models-for-stream-networks-hoef-et-al-2014-peterson-et-al-2020">2.7.3.5. 3.3. Make inputs required to create an SSN object, a kind of R object necessary to fit a Spatial Linear Models for Stream Networks (Hoef et al. 2014, Peterson et al. 2020).</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#species-distribution-modelling">2.7.4. 5. Species distribution modelling</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#model-calibration-and-evaluation">2.7.4.1. 5.1. Model calibration and evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="#model-ensamble">2.7.4.2. 5.2. Model ensamble</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="Modeling_debris_flow_source_areas_Txomin_Bornaetxea.html">2.8. Txomin Bornaetxea: Modeling debris flow source areas</a></li>
<li class="toctree-l2"><a class="reference internal" href="Prediction_of_AGB_using_RFR_SVR_FFNN_Ritwika_Mukhopadhyay.html">2.9. Ritwika Mukhopadhyay: Comparative Analysis of the prediction of AGB using Random Forest Regression, Support Vector Machine for Regression &amp; FeedForward Neural Network</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">OUTDOOR</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../OUTDOOR/outdoor_orientering.html">Do not get lost in the wilderness</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">TALKS</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../TALKS/intelligent_modelling.html">Intelligent modelling in time and space: combine GeoComputation and Machine Learning for  environmental application.</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">ADMIN</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../ADMIN/00_pktools_gdrive_install.html">Install pktools on the gdrive and be able to use from any Colab</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ADMIN/video.html">Video tips</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ADMIN/Compiling_OTB.html">Compiling OTB from source</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Spatial Ecology's code documentation</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../index.html"><span class="section-number">1. </span>2021 SWEDEN</a> &raquo;</li>
      <li><span class="section-number">2.7. </span>Yusdiel Torres-Cambas: Distribution of freshwater biodiversity across Cuba</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/STUDENTSPROJECTS/Proj_2022_Matera/Distributionof_Fresh_water_Biodiversity_AcrossCuba_Yusdiel_Torres.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="yusdiel-torres-cambas-distribution-of-freshwater-biodiversity-across-cuba">
<h1><span class="section-number">2.7. </span>Yusdiel Torres-Cambas: Distribution of freshwater biodiversity across Cuba<a class="headerlink" href="#yusdiel-torres-cambas-distribution-of-freshwater-biodiversity-across-cuba" title="Permalink to this headline"></a></h1>
<p><a class="reference external" href="http://spatial-ecology.net/docs/source/STUDENTSPROJECTS/Proj_2022_Matera/Distributionof_Fresh_water_Biodiversity_AcrossCuba_Yusdiel_Torres.pdf">Presentation</a><br /><a class="reference external" href="https://youtu.be/txgG2FRvln4">Video recording</a></p>
<section id="introduction">
<h2><span class="section-number">2.7.1. </span>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline"></a></h2>
<p>Freshwater ecosystems are amongst the most biodiverse and the most important providers of ecosystem services to humans globally. Simultaneously, these ecosystems are also amongst the most threatened in the world. Threats include habitat loss and fragmentation, overharvesting, flow alteration, contamination and introduction of invasive species; all of which could be exacerbated by the influence of climate change in the future.
Species distribution is a basic information required to develop conservation strategies for freshwater ecosystems. Unfortunately, we lack this information for many of the tropical freshwater species. Species distribution models are a useful tool to fill this knowledge gap. In the present project, the potential distribution of species of freshwater insects, crustaceans, mollusk, amphibians and fishes was modeled.
The first part of the project is dedicated to prepare the model inputs. These include download, crop and reproject the layers of predictor variables, aggregate this variables by sub-basins and generate pseudoabsences for the models. The second part includes the modelling procedure.</p>
</section>
<section id="predictor-variables">
<h2><span class="section-number">2.7.2. </span>1. Predictor variables<a class="headerlink" href="#predictor-variables" title="Permalink to this headline"></a></h2>
<p>All the layers were cropped to the extent of Cuba and reprojected (Cuba Norte projection, EPSG: 3795).</p>
<section id="download-and-mosaic-tiles-of-a-digital-elevation-model">
<h3><span class="section-number">2.7.2.1. </span>1.1. Download and mosaic tiles of a digital elevation model<a class="headerlink" href="#download-and-mosaic-tiles-of-a-digital-elevation-model" title="Permalink to this headline"></a></h3>
<div class="highlight-{bash eval=FALSE} notranslate"><div class="highlight"><pre><span></span>#Download and mosaic DEM tiles 
#!/bin/bash

INPUT=/media/sf_Nextcloud/matera/raster_layers/wgs84
OUTPUT=/media/sf_Nextcloud/matera/raster_layers/wgs84
#INPUTV=/media/sf_Nextcloud/matera/vector_layers

#Download and unpack DEM tiles for Cuba
wget --user=hydrography --password=rivernetwork -P $OUTPUT http://hydro.iis.u-tokyo.ac.jp/~yamadai/MERIT_Hydro/distribute/v1.0/elv_n00w090.tar
tar -xvf $INPUT/elv_n00w090.tar -C $OUTPUT

#Mosaic tiles
gdalbuildvrt -overwrite $OUTPUT/merit_hydro_cuba_wgs8.vrt $INPUT/elv_n00w090/n15w075_elv.tif $INPUT/elv_n00w090/n20w075_elv.tif $INPUT/elv_n00w090/n15w080_elv.tif $INPUT/elv_n00w090/n20w085_elv.tif $INPUT/elv_n00w090/n20w080_elv.tif
gdal_translate -co COMPRESS=DEFLATE -co ZLEVEL=9 $OUTPUT/merit_hydro_cuba_wgs8.vrt $OUTPUT/dem_wgs8.tif
</pre></div>
</div>
</section>
<section id="download-bioclimatic-variables">
<h3><span class="section-number">2.7.2.2. </span>1.2. Download bioclimatic variables<a class="headerlink" href="#download-bioclimatic-variables" title="Permalink to this headline"></a></h3>
<div class="highlight-{bash eval=FALSE} notranslate"><div class="highlight"><pre><span></span>### Download a list of raster layers from CHELSA website
#that represent bioclimatic variables for present climate
#!/bin/bash

#links_bio.txt: URLs of files to be downloaded

INPUT=/media/sf_Nextcloud/matera/scripts
OUTPUT=/media/sf_Nextcloud/matera/raster_layers/wgs84

wget -i $INPUT/links_bio.txt -P $OUTPUT
</pre></div>
</div>
</section>
<section id="download-and-mosaic-tiles-of-tree-cover">
<h3><span class="section-number">2.7.2.3. </span>1.3. Download and mosaic tiles of tree cover<a class="headerlink" href="#download-and-mosaic-tiles-of-tree-cover" title="Permalink to this headline"></a></h3>
<div class="highlight-{bash eval=FALSE} notranslate"><div class="highlight"><pre><span></span>
#Download  and mosaic Global 2010 Tree Cover (30 m)
#!/bin/bash

INPUT=/media/sf_Nextcloud/matera/raster_layers/wgs84
OUTPUT=/media/sf_Nextcloud/matera/raster_layers/wgs84
#INPUTV=/media/sf_Nextcloud/matera/vector_layers

#Download tree cover tiles for Cuba
wget -P $OUTPUT https://glad.umd.edu/Potapov/TCC_2010/treecover2010_20N_080W.tif
wget -P $OUTPUT https://glad.umd.edu/Potapov/TCC_2010/treecover2010_30N_080W.tif
wget -P $OUTPUT https://glad.umd.edu/Potapov/TCC_2010/treecover2010_30N_090W.tif

#Mosaic tiles
gdalbuildvrt -overwrite $OUTPUT/tree_wgs84.vrt $INPUT/treecover2010_20N_080W.tif $INPUT/treecover2010_30N_080W.tif $INPUT/treecover2010_30N_090W.tif
gdal_translate -co COMPRESS=DEFLATE -co ZLEVEL=9 $INPUT/tree_wgs84.vrt $OUTPUT/tree_wgs84.tif
</pre></div>
</div>
</section>
<section id="calculate-slope">
<h3><span class="section-number">2.7.2.4. </span>1.4. Calculate slope<a class="headerlink" href="#calculate-slope" title="Permalink to this headline"></a></h3>
<div class="highlight-{bash eval=FALSE} notranslate"><div class="highlight"><pre><span></span>#Calculate slope
#!/bin/bash
INPUT=/media/sf_Nextcloud/matera/raster_layers/wgs84
OUTPUT=/media/sf_Nextcloud/matera/raster_layers/wgs84

#Slope
gdaldem slope -s 111120 -alg ZevenbergenThorne -co COMPRESS=LZW -co ZLEVEL=9 $INPUT/dem_wgs8.tif $OUTPUT/slope_wgs84.tif
</pre></div>
</div>
</section>
<section id="crop-and-reproject">
<h3><span class="section-number">2.7.2.5. </span>1.5. Crop and reproject<a class="headerlink" href="#crop-and-reproject" title="Permalink to this headline"></a></h3>
<div class="highlight-{bash eval=FALSE} notranslate"><div class="highlight"><pre><span></span>#Crop and reproject (Cuba Norte EPSG:3795)
#!/bin/bash

VECTORPATH=/media/sf_Nextcloud/matera/vector_layers
INPUTPATH=/media/sf_Nextcloud/matera/raster_layers/wgs84
OUTPUTPATH=/media/sf_Nextcloud/matera/raster_layers/cubanorte

#Download a vector file of Cuba. This vector file is used to crop all raster
wget -P $VECTORPATH https://data.humdata.org/dataset/32b4ba2e-2ee5-4b2b-a7e4-9e4d323ffe73/resource/42e19431-86a8-451c-a903-d60ec5ec16ad/download/cub_adma_2019_shp.zip
unzip -o $VECTORPATH/cub_adma_2019_shp.zip  -d  $VECTORPATH

#Crop and reproject DEM
#Crop
gdalwarp   -cutline $VECTORPATH/cub_admbnda_adm0_2019.shp -cl cub_admbnda_adm0_2019 -crop_to_cutline $INPUTPATH/dem_wgs8.tif  -dstnodata -9999 $INPUTPATH/dem_wgs8_crop.tif
# Reproject
gdalwarp -t_srs EPSG:3795 -r bilinear $INPUTPATH/dem_wgs8_crop.tif $OUTPUTPATH/dem.tif

#Crop and reproject bioclimatic layers
for file in $INPUT/CHELSA*.tif; do
   filename=$(basename $file .tif | cut -f 3 -d &#39;_&#39;)
   echo $file
   echo $filename
   gdalwarp -cutline $VECTORPATH/cub_admbnda_adm0_2019.shp -cl cub_admbnda_adm0_2019 -crop_to_cutline $file  -co COMPRESS=LZW -co ZLEVEL=9 -dstnodata -9999 $INPUT/bio$filename.tif -overwrite
   gdalwarp  -t_srs EPSG:3795 -r bilinear $INPUT/bio$filename.tif  -co COMPRESS=LZW -co ZLEVEL=9 -dstnodata -9999 $OUTPUT/bio$filename.tif -overwrite
done

#Crop and reproject percent tree cover
#Crop
gdalwarp   -cutline $VECTORPATH/cub_admbnda_adm0_2019.shp -cl cub_admbnda_adm0_2019 -crop_to_cutline $INPUTPATH/tree_wgs84.tif  -dstnodata $INPUTPATH/tree_wgs84_crop.tif
# Reproject
gdalwarp -t_srs EPSG:3795 -r bilinear $INPUTPATH/tree_wgs84_crop.tif $OUTPUTPATH/tree.tif

#Crop and reproject slope
#Crop
gdalwarp   -cutline $VECTORPATH/cub_admbnda_adm0_2019.shp -cl cub_admbnda_adm0_2019 -crop_to_cutline $INPUTPATH/slope_wgs84.tif  -dstnodata -9999 $INPUTPATH/slope_wgs84_crop.tif
# Reproject
gdalwarp -t_srs EPSG:3795 -r bilinear $INPUTPATH/slope_wgs84_crop.tif $OUTPUTPATH/slope.tif
</pre></div>
</div>
</section>
</section>
<section id="stream-network-and-sub-basins">
<h2><span class="section-number">2.7.3. </span>2. Stream network and sub-basins<a class="headerlink" href="#stream-network-and-sub-basins" title="Permalink to this headline"></a></h2>
<p>The digital elevation model was used to extract a stream network and sub-basins associated with each stream reach
in GRASS-GIS. All predictors were aggregated (mean) by sub-basin.</p>
<section id="make-a-grass-gis-database">
<h3><span class="section-number">2.7.3.1. </span>2.1. Make a GRASS GIS database<a class="headerlink" href="#make-a-grass-gis-database" title="Permalink to this headline"></a></h3>
<div class="highlight-{bash eval=FALSE} notranslate"><div class="highlight"><pre><span></span>#Make a GRASS GIS database

#Path to the database
export GRASS=/media/sf_Nextcloud/matera/grassdatabase
echo $GRASS
mkdir $GRASS

#Path to a DEM. The DEM is used to set the resolution and CRS of the GRASS-GIS
#location  
export DEMPATH=/media/sf_Nextcloud/matera/raster_layers/cubanorte/dem_3795.tif
echo $DEMPATH

### Create the GRASS GIS database and enter GRASS:
grass78  -text -c $DEMPATH  $GRASS/cubanorte
</pre></div>
</div>
</section>
<section id="extract-flow-direction-flow-accumulation-stream-network-basins-and-sub-basins">
<h3><span class="section-number">2.7.3.2. </span>2.2. Extract flow direction, flow accumulation, stream network, basins and sub-basins<a class="headerlink" href="#extract-flow-direction-flow-accumulation-stream-network-basins-and-sub-basins" title="Permalink to this headline"></a></h3>
<div class="highlight-{bash eval=FALSE} notranslate"><div class="highlight"><pre><span></span>#Extract flow direction, flow accumulation, stream network, basins and sub-
#basins

#Path to the database
export GRASS=/media/sf_Nextcloud/matera/grassdatabase
echo $GRASS
mkdir $GRASS

#Path to a DEM
export INPUT=/media/sf_Nextcloud/matera/raster_layers/cubanorte/dem_3795.tif
echo $INPUT

#Output path
export OUTPUT=/media/sf_Nextcloud/matera/raster_layers/cubanorte
export OUTPUTV=/media/sf_Nextcloud/matera/vector_layers/cubanorte
# Open a GRASS GIS session
grass78  -text $GRASS/cubanorte/PERMANENT

### Import an elevation model into GRASS:
r.in.gdal $INPUT   output=elevation
#Visualize DEM
d.mon wx0
d.rast elevation

# flow direction, flow accumulation, stream
r.watershed -b -a  elevation=elevation  drainage=dirs   stream=stream  accumulation=accums  threshold=500 convergence=10  --o
# basins
g.extension r.stream.basins
r.stream.basins  direction=dirs  stream_rast=stream  basins=basins_last  -l  --o
# sub-basins
r.stream.basins  direction=dirs  stream_rast=stream  basins=sub_basins  --o
r.grow  input=sub_basins output=sub_basins_g --overwrite
# stream network with stream order
g.extension r.stream.order
r.stream.order  stream_rast=stream   elevation=elevation  direction=dirs  accumulation=accums  strahler=stream_strahler stream_vect=streams_v  --o

# Save results

r.out.gdal  input=basins_last   output=$OUTPUT/basins.tif      type=Int32  nodata=-9999  --o  -c  -m  createopt=&quot;COMPRESS=LZW,ZLEVEL=9&quot;
r.out.gdal  input=sub_basins_g    output=$OUTPUT/sub_basins.tif   type=Int32  nodata=-9999  --o  -c  -m -f createopt=&quot;COMPRESS=LZW,ZLEVEL=9&quot;

v.out.ogr  input=streams_v  output=$OUTPUTV/streams_v.gpkg   format=GPKG  type=line  --overwrite
r.out.gdal  input=accums   output=$OUTPUT/accums.tif      type=Int32  nodata=-9999  --o  -c  -m -f  createopt=&quot;COMPRESS=LZW,ZLEVEL=9&quot;
r.out.gdal  input=dirs   output=$OUTPUT/dirs.tif      type=Int32  nodata=-9999  --o  -c  -m  -f createopt=&quot;COMPRESS=LZW,ZLEVEL=9
</pre></div>
</div>
<p><img alt="../../_images/stream.png" src="../../_images/stream.png" />
<em>Figure 1. Stream network extracted with GRASS-GIS</em></p>
<p><img alt="../../_images/subbasins.png" src="../../_images/subbasins.png" />
<em>Figure 2. Sub-basins extracted with GRASS-GIS</em></p>
</section>
<section id="aggregate-predictors-by-sub-basin">
<h3><span class="section-number">2.7.3.3. </span>2.3. Aggregate predictors by sub-basin<a class="headerlink" href="#aggregate-predictors-by-sub-basin" title="Permalink to this headline"></a></h3>
<div class="highlight-{bash eval=FALSE} notranslate"><div class="highlight"><pre><span></span>#Aggregate predictors by sub-basin

#Path to the database
export GRASS=/media/sf_Nextcloud/matera/grassdatabase
echo $GRASS

#Input path
export INPUT=/media/sf_Nextcloud/matera/raster_layers/cubanorte

#Output path
export OUTPUT=/media/sf_Nextcloud/matera/raster_layers/cubanorte_aggregate

# Open a GRASS GIS session
grass78  -text $GRASS/cubanorte/PERMANENT

#Import sub-basins
r.in.gdal /media/sf_Nextcloud/matera/raster_layers/cubanorte/sub_basins.tif output=subb --overwrite

for file in $INPUT/*.tif; do

   filename=$(basename $file .tif)
   echo $file
   echo $filename
   r.in.gdal $file output=predictor --overwrite
   r.grow  input=predictor radius=5 output=predictor --overwrite
   r.stats.zonal method=average cover=predictor base=subb output=predictor_aggr --overwrite
   r.out.gdal  input=predictor_aggr output=$OUTPUT/$filename.tif type=Float32  nodata=-9999  --o  -c  -m -f  createopt=&quot;COMPRESS=LZW,ZLEVEL=9&quot;
done
</pre></div>
</div>
<p><img alt="../../_images/tree.png" src="../../_images/tree.png" />
<em>Figure 3. Percent of tree cover aggregated by sub-basin.</em></p>
<p><img alt="../../_images/slope.png" src="../../_images/slope.png" />
<em>Figure 4. Slope aggregated by sub-basin.</em></p>
<p><img alt="../../_images/accum.png" src="../../_images/accum.png" />
<em>Figure 5. Flow accumulation aggregated by sub-basin.</em></p>
<p><img alt="../../_images/bio01.png" src="../../_images/bio01.png" />
<em>Figure 6. Annual mean temperature (x 10) aggregated by sub-basin.</em></p>
<p><img alt="../../_images/bio02.png" src="../../_images/bio02.png" />
<em>Figure 7. Mean diurnal range (x 10) aggregated by sub-basin.</em></p>
<p><img alt="../../_images/bio04.png" src="../../_images/bio04.png" />
<em>Figure 8. Temperature seasonality aggregated by sub-basin.</em></p>
<p><img alt="../../_images/bio12.png" src="../../_images/bio12.png" />
<em>Figure 9. Annual precipitation (mm).</em></p>
<p><img alt="../../_images/bio14.png" src="../../_images/bio14.png" />
<em>Figure 10. Precipitation of the driest month (mm).</em></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>## 3. Biodiversity data
Occurrence records were obtained from the scientific literature, unpublished thesis, Cuban scientific collections and online databases (GBIF, https://www.gbif.org, iNaturalist, https://www.inaturalist.org/).
Pseudo-absences were selected at random from potential unsuitable sub-basins for the presence of each species, previously identified through a one-class support vector machine analysis (i.e. two-step pseudo-absence selection method, Senay et al., 2013). The number of selected pseudo-absences was set to keep a constant prevalence (i.e. proportion presences / pseudoabsences) of 0.1 through all species (Barbet-Massin et al., 2012).

### 3.1. Creates a map with prediction points. One point per stream reach. Extract predictor values at each point
```{r  eval=FALSE}
R
#Creates a map with prediction points. One point per stream reach. Extract predictor values at each point 

library(dplyr)
library(sf)
library(raster)
library(maptools)

# Import presences
  pres &lt;- st_read(&quot;./vector_layers/cubanorte/oc.gpkg&quot;) 
  
# Import streams
  streams &lt;- st_read(&quot;./vector_layers/cubanorte/streams_v.gpkg&quot;) %&gt;%
    filter(!(length==0))

# Transform stream to an sp object
  streams &lt;- as_Spatial(streams)

# Get coordinates of the middle point of each stream segment
  center_points &lt;- getSpatialLinesMidPoints(streams)%&gt;%
    as.data.frame(center_points@coords) %&gt;%
      st_as_sf(coords = c(&quot;coords.x1&quot;,&quot;coords.x2&quot;))%&gt;%
        st_set_crs(3795)

  center_points &lt;- as_Spatial(center_points)

# Snap points to the nearest line
  center_points &lt;- snapPointsToLines(center_points, streams)

# Get ID of each stream segment
  stream_id &lt;- streams$stream

# Creates an sf object with stream IDs and middle point of each stream
  prediction_sites &lt;- as(center_points, &quot;sf&quot;)%&gt;%
    dplyr::select(geometry)
  
  prediction_sites$stream_id &lt;- stream_id

# Extract predictor values at prediction points
  list_pred &lt;- list.files(&quot;./raster_layers/cubanorte_aggregate&quot;, full.names = T)
  
  predict_stack &lt;- raster::stack(list_pred)
  
  predict_val &lt;- extract(predict_stack, prediction_sites)
  
# Standardize variables
  predict_val &lt;- predict_val %&gt;%
    scale(center = T, scale = T)
  
  prediction_sites &lt;- cbind(prediction_sites, predict_val) %&gt;%
    st_set_crs(3795)

# Save results
  st_write(prediction_sites, &quot;./sdm/input/prediction_sites.gpkg&quot;,
         driver = &quot;GPKG&quot;, append = F)
</pre></div>
</div>
</section>
<section id="make-maps-with-presence-and-pseudoabsences">
<h3><span class="section-number">2.7.3.4. </span>3.2. Make maps with presence and pseudoabsences<a class="headerlink" href="#make-maps-with-presence-and-pseudoabsences" title="Permalink to this headline"></a></h3>
<div class="highlight-{r eval=FALSE} notranslate"><div class="highlight"><pre><span></span>#Creates a map with presence and pseudoabsences 

R

library(dplyr)
library(sf)
library(raster)
library(e1071)

# Keep only one observation point per sub-basin and extract predictor values at 
# each observation point
  pres &lt;- st_read(&quot;./vector_layers/cubanorte/oc.gpkg&quot;)
  sub_bas &lt;- raster(&quot;./raster_layers/cubanorte/sub_basins.tif&quot;)
 
  pres_ids &lt;- extract(sub_bas, pres)%&gt;%
    unique()
  
  predict_points &lt;- st_read(&quot;./sdm/input/prediction_sites.gpkg&quot;)
  
  pres_pred &lt;- predict_points %&gt;%
    filter(stream_id %in% pres_ids)
  
# Inputs of the OCSVM model 
  occur_vars &lt;- pres_pred %&gt;%
    dplyr::select(-stream_id) %&gt;%
      st_drop_geometry()
    
  bkgr_vars &lt;- predict_points %&gt;%
    dplyr::select(-stream_id) %&gt;%
      st_drop_geometry()
  
# Model fitting
  svm_model &lt;- svm(occur_vars, y=NULL, type=&#39;one-classification&#39;, nu=0.5)
    
# Make predictions with OCSVM
  env_prof_r &lt;- predict(svm_model, bkgr_vars)
    
# Transform predictions from TRUE/FALSE to 1/0
  env_prof_r &lt;- ifelse(env_prof_r==&quot;FALSE&quot;,0,1)
    
# Add sub-basins ids
  env_prof_r &lt;- data.frame(predict_points$stream_id, &quot;pres_abs&quot; = env_prof_r)
    
# Extract sub-basins IDs at sub-basins where the species is not recorded and
# the environmental profiling predicted an absence
  abs_ids &lt;- predict_points %&gt;%
    filter(!(stream_id %in% env_prof_r$stream_id) &amp; 
      !(stream_id %in% pres_pred$stream_id))
  
# Generates a random sample of sub-basin IDs where the species is 
# potentially absent (no records or absence predicted by OCSVM).
# The number of random points is 10 times the number of occurrences
  pseudo_streams_ids &lt;- sample(x = abs_ids$stream_id, size = 10*nrow(pres_pred))
    
# Make an sf object with random points from previous step
  pseudoabs_map &lt;- predict_points %&gt;%
    filter(stream_id %in% pseudo_streams_ids)

# Add a column with absences to the sf object from previous step
  pseudoabs_map$pres_abs &lt;- 0
  
# Add a column with presences to the sf object with occurrence points
  pres_pred$pres_abs &lt;- 1
    
# Bind presences and absences in an sf object
  obser_sites &lt;- rbind(pres_pred, pseudoabs_map) %&gt;%
    st_set_crs(3795)
    
# Save results
  st_write(obser_sites, &quot;./sdm/input/obs.gpkg&quot;, append = F)
</pre></div>
</div>
</section>
<section id="make-inputs-required-to-create-an-ssn-object-a-kind-of-r-object-necessary-to-fit-a-spatial-linear-models-for-stream-networks-hoef-et-al-2014-peterson-et-al-2020">
<h3><span class="section-number">2.7.3.5. </span>3.3. Make inputs required to create an SSN object, a kind of R object necessary to fit a Spatial Linear Models for Stream Networks (Hoef et al. 2014, Peterson et al. 2020).<a class="headerlink" href="#make-inputs-required-to-create-an-ssn-object-a-kind-of-r-object-necessary-to-fit-a-spatial-linear-models-for-stream-networks-hoef-et-al-2014-peterson-et-al-2020" title="Permalink to this headline"></a></h3>
<p>References:</p>
<ol class="simple">
<li><p>Hoef, J.M. Ver, Peterson, E.E., Clifford, D., Shah, R., 2014. SSN: An R package
for spatial statistical modeling on stream networks. J. Stat. Softw. 56, 1–45.</p></li>
<li><p>Peterson, E., Scha, R.B., Id, M.K., Szo, E., 2020. Preparing GIS data for
analysis of stream monitoring data: The R package
openSTARS 1–10. https://doi.org/10.1371/journal.pone.0239237</p></li>
</ol>
<p>The first part of the script initiate a GRASS-GIS session and import rasters with flow direction and flow accumulation and vector maps with a stream network and prediction sites into GRASS-GIS.</p>
<div class="highlight-{bash eval=FALSE} notranslate"><div class="highlight"><pre><span></span>#!/bin/bash

#Input and output path

export INPUTDIR=/media/sf_Nextcloud/matera/
export OUTPUTDIR=/media/sf_Nextcloud/matera/sdm/input
echo $INPUTDIR
echo $OUTPUTDIR



# Make a GRASS location with a projected CRS for Cuba (EPSG: 3795) and load GRASS GIS.

grass78  -text -c $INPUTDIR/raster_layers/cubanorte/dem_3795.tif $INPUTDIR/grass_openstars

#Open an existing GRASS location
#grass78  -text $INPUTDIR/grass_openstars/PERMANENT

# Check current location projection
g.proj -wf

# Import maps of flow direction, flow accumulation, stream network,
# sampling sites and prediction sites into GRASS
#Map&#39;s name for flow direction, flow accumulation, stream network and
#sampling sites must be &quot;dirs&quot;, &quot;accums&quot;, &quot;streams_v&quot; and &quot;sites_o&quot; respectivelly

r.in.gdal $INPUTDIR/raster_layers/cubanorte/dirs.tif output=dirs --overwrite
r.in.gdal $INPUTDIR/raster_layers/cubanorte/accums.tif output=accums --overwrite
v.in.ogr $INPUTDIR/vector_layers/cubanorte/streams_v.gpkg output=streams_v --overwrite
v.in.ogr $INPUTDIR/sdm/input/prediction_sites.gpkg output=pred_sites_o --overwrite


#Rename columns in the attribute table of streams_v. This is required because
# openSTARS exports the results as Esri shapefiles, that requires column names length
# of 10 charactres or less

v.db.renamecolumn map=streams_v column=next_stream,next_str
v.db.renamecolumn map=streams_v column=scheidegger,scheid
v.db.renamecolumn map=streams_v column=source_elev,s_elev
v.db.renamecolumn map=streams_v column=outlet_elev,o_elev

#Check the attribute table
db.columns table=streams_v
</pre></div>
</div>
<p>The second part of the script calls R from within the GRASS-GIS session of the previous step, <strong>(1)</strong> check and correct the stream network and <strong>(2)</strong> prepare edges, <strong>(3)</strong> observation sites and <strong>(4)</strong> prediction sites.<br /><strong>(1)check and correct the stream network</strong>: Stream network may have stream confluences of more than three segments, i.e. where more than two line segments flow into a node. These parts must be corrected before further processing.<br /><strong>(2)prepare edges</strong>: Information (e.g. reach contributing area, upstream catchment areas, attributes related with the topology of the stream network) needed for the SSN object are derived for the streams and stored in a new vector map edges.<br /><strong>(3) prepare observation sites and (4) prediction sites</strong>: snap points to the stream network, and add some attributes (e.g. distance to the outlet, reach identifier, network identifier)</p>
<div class="highlight-{r eval=FALSE} notranslate"><div class="highlight"><pre><span></span>R
library(openSTARS)
library(sp)
library(rgdal)
library(dplyr)
library(rgrass7)
use_sp()

# Correct the network where more than two line segments flow into a node
correct_compl_confluences()

#Prepare edges. Information needed for the SSN object are derived for the
#streams and stored in a new vector map &quot;edges&quot; based on streams_v
calc_edges()

#Read files with observation points 
  path_obs_files &lt;- &quot;/media/sf_Nextcloud/matera/sdm/input/obs_sites&quot;
  obs_files &lt;- list.files(path=path_obs_files, 
                          pattern = &quot;.gpkg&quot;,
                          full.names = T)%&gt;%
    lapply(readOGR)
#Get the names of files
  files_names    &lt;- gsub(&quot;.gpkg&quot;,&quot;&quot;,
                         list.files(path_obs_files,full.names = FALSE),
                         fixed = TRUE)
#Import maps with observation sites of each species into GRASS
  for (i in 1:length(files_names)) {
    writeVECT(obs_files[[i]], vname = &quot;sites_o&quot;, v.in.ogr_flags = &quot;overwrite&quot;)
    calc_sites(predictions = &quot;pred_sites_o&quot;)
    
#Write all data to an SSN folder
    ssn_dir &lt;- file.path(&quot;./media/sf_Nextcloud/matera/sdm/input/outputOpenSTARS&quot;, files_names[i])
    export_ssn(ssn_dir, predictions = &quot;pred_sites&quot;, delete_directory = TRUE)
  }
  
</pre></div>
</div>
</section>
</section>
<section id="species-distribution-modelling">
<h2><span class="section-number">2.7.4. </span>5. Species distribution modelling<a class="headerlink" href="#species-distribution-modelling" title="Permalink to this headline"></a></h2>
<section id="model-calibration-and-evaluation">
<h3><span class="section-number">2.7.4.1. </span>5.1. Model calibration and evaluation<a class="headerlink" href="#model-calibration-and-evaluation" title="Permalink to this headline"></a></h3>
<div class="highlight-{r eval=FALSE} notranslate"><div class="highlight"><pre><span></span>
#Predict species distribution with a spatial linear model for stream network

library(SSN)
library(dplyr)



list_ssn_dirs &lt;- list.dirs(path = &quot;C:/Users/torres/Desktop/temporal&quot;, recursive = F)

load(&quot;./SDM/CorMdls.RData&quot;)



####### Functions

#Model selection Spatial Stream Network
#Non-spatial models. Fits all possible models and select the one with 
#lowest AUC
SSNparam &lt;- function(SSNobj, CorMdls)
{
  
  # SSNparam &lt;- function(SSNobj, CorMdls)
  #   {
  library(foreach)
  library(doParallel)
  library(MuMIn)
  library(purrr)
  # Selecting a non-spatial model
  DataNsp &lt;- getSSNdata.frame(SSNobj, Name = &quot;Obs&quot;)%&gt;%
    dplyr::select(accums_av:slope_av, pres_abs)
  
  ModelNsp &lt;- try(glm(formula = pres_abs ~ ., 
                      data = DataNsp,
                      family = binomial))
  options(na.action = &quot;na.fail&quot;)
  ListModelNsp &lt;- dredge(ModelNsp)
  BestModelNsp &lt;- eval(attributes(ListModelNsp)$model.calls[[1]])
  
  #Get Residuals
  SSNobj@obspoints@SSNPoints[[1]]@point.data$RES &lt;- resid(BestModelNsp)
  #Spatial models
  #Setup of a parallel backend
  print(&quot;Selecting a spatial autocorrelation model...&quot;)
  n.cores &lt;- parallel::detectCores() - 1
  my.cluster &lt;- parallel::makeCluster(
    n.cores,
    type = &quot;PSOCK&quot;
  )
  doParallel::registerDoParallel(cl = my.cluster)
  ssn_cor_test &lt;- foreach (m = 1:length(CorMdls), .packages = &quot;SSN&quot;, .errorhandling=&quot;remove&quot;) %dopar%  {
    #   print(paste(eval(CorMdls[[m]])))
    glmssn(RES ~ 1, SSNobj, CorModels= eval(CorMdls[[m]]),
           addfunccol = &quot;computed.afv&quot;)
  }
  parallel::stopCluster(cl = my.cluster)
  # #Models AIC
  cor_modl_AIC &lt;- InfoCritCompare(keep(ssn_cor_test, is.list))
  #Results
  formula &lt;- BestModelNsp$formula
  model &lt;- eval(CorMdls[[which.min(cor_modl_AIC$AIC)]])
  return(list(&quot;formula&quot; = formula, &quot;model&quot; = model, &quot;modelsAIC&quot; = cor_modl_AIC))
  #return(list(&quot;formula&quot; = formula))
  
}


#Function to calculates metrics of model performance
# obsPresAbs: a vector with presence / absence, test dataset
# predProb: predicted probabilities on test dataset with a model calibrated with
# train dataset
# The function returns a list with two dataframe, one with thresholds used to transform 
# predicted probabilities to presence / absence and calculate threshold-based
# performance metrics and other with performance metrics

eval_mod &lt;- function(idsPresabsProb)
{
  #devtools::install_github(&quot;meeliskull/prg/R_package/prg&quot;, force = T)
  require(prg)
  require(PresenceAbsence)
  require(modEvA)
  require(dplyr)
  require(tibble)
  
  #Calculates AUC of PRG
  AUC_PRG &lt;- prg::calc_auprg(prg::create_prg_curve(labels = idsPresabsProb[,2],
                                                   pos_scores = idsPresabsProb[,3]))
  
  
  #Calculates AUC of ROC
  AUC_ROC &lt;- AUC(obs = idsPresabsProb[,2], 
                 pred = idsPresabsProb[,3], 
                 plot = F,
                 simplif = T) 
  
  # Calculates threshold based methods to asses model performance
  # Calculate thresholds 
  thresh &lt;- idsPresabsProb %&gt;%
    optimal.thresholds(opt.methods = c(&quot;Sens=Spec&quot;))
  
  #Calculate threshold based metrics. Use the threshold that minimize the 
  #difference between sensibility and specificity
  
  perform &lt;- threshMeasures(obs = idsPresabsProb[,2], 
                            pred = idsPresabsProb[,3], 
                            simplif = T, thresh = thresh[,2], standardize = T,
                            measures = c(&quot;Sensitivity&quot;, &quot;Specificity&quot;, &quot;Omission&quot;, &quot;Commission&quot;, &quot;TSS&quot;))%&gt;%
    as.data.frame()%&gt;%
    rownames_to_column(var = &quot;Measures&quot;)%&gt;%
    add_row(Measures = c(&quot;AUC_ROC&quot;, &quot;AUC_PRG&quot;), Value = c(AUC_ROC, AUC_PRG))   #Add 
  #non-threshold based measures to a data frame with all metrics
  #Make a list with thresholds and performance metrics 
  func_output &lt;- list(&quot;threshold&quot; = thresh, &quot;performance&quot; = perform)
  #Return the list
  return(func_output)
}

#Get the names of files. Will be used to save results
files_names &lt;- list.files(path = &quot;C:/Users/torres/Desktop/temporal&quot; ,full.names = FALSE)
                  


#Loop through all species

for (sp in 1:length(list_ssn_dirs)) {
  time_sp &lt;- system.time({
    tryCatch({
      
    #1 Imports SSN object
      print(paste(&quot;Start&quot;,files_names[sp] ,sep = &quot; &quot;))
    print(&quot;Importing SSN object...&quot;)
    ssn_dir &lt;- list_ssn_dirs[sp]
    ssn_sp_i &lt;- importSSN(ssn_dir, predpts = &quot;pred_sites&quot;)
  
    #2 Generating an additive function value (necessary for Tail-up models)
    print(&quot;Generating an additive function value...&quot;)
    ssn_sp_i &lt;- additive.function(ssn_sp_i, &quot;H2OArea&quot;,&quot;computed.afv&quot;)
    
    #3 Calculates distance matrix
    print(&quot;Calculating distance matrix...&quot;)
    createDistMat(ssn_sp_i, predpts = &quot;pred_sites&quot;, o.write = T)
    
    
    ## Model parameter calibration
    glmssnParam &lt;- SSNparam(ssn_sp_i, CorMdls)
    
    # Output path
    output_path &lt;- paste0(&quot;./SDM/output/indepModels/&quot;,files_names[sp])
    ifelse(!dir.exists(output_path), dir.create(output_path), FALSE)
    output_path3 &lt;- paste0(&quot;./SDM/output/ClimateScenarios/&quot;,files_names[sp])
    ifelse(!dir.exists(output_path3), dir.create(output_path3), FALSE)
    #Matrix to save results
    thres &lt;- matrix(nrow = 1, ncol = 10)
    perform &lt;- matrix(nrow = 2, ncol = 10)
    predict_sites &lt;- getSSNdata.frame(ssn_sp_i, Name = &quot;pred_sites&quot;)
    PredProb &lt;- matrix(nrow = nrow(predict_sites), ncol = 11)
    PredProb[,11] &lt;- predict_sites$stream
    # Import data frames with sub-catchment ids of calibration and evaluation
    # data sets
    CalDf &lt;- read.csv(paste0(&quot;./SDM/input/occurr/&quot;,files_names[sp],&quot;/calib.csv&quot;))
    EvalDf &lt;- read.csv(paste0(&quot;./SDM/input/occurr/&quot;,files_names[sp],&quot;/eval.csv&quot;))
    
    #Model training and testing through a 10 split sampling strategy
    for (r in 1:10) {
    tryCatch({
    #Data frame with observation points 
    ssn_test_dataDF &lt;- getSSNdata.frame(ssn_sp_i)
    
    #Ids of observations selected for evaluation 
    EvaIds &lt;- EvalDf[,r]
    
    #Insert NAs in the column of the response variable (pres_abs) in the observations
    #selected for evaluation
    ssn_test_dataDF[ssn_test_dataDF$stream %in% EvaIds,&quot;pres_abs&quot;] &lt;- NA
    
    #Put the data frame with NAs in the SSN object. 
    ssn_calib_data &lt;- putSSNdata.frame(ssn_test_dataDF, ssn_sp_i)
    #With this, the regression omits observations with NAs and the model is fitted
    # only on the calibration data set 
    options(na.action = &quot;na.omit&quot;)
    
    #Fit the model with the calibration data set and parameters
    CalibSsn &lt;- try(glmssn(formula =  glmssnParam$formula,
                                    family = &quot;binomial&quot;,
                                    ssn_calib_data,
                                    CorModels = glmssnParam$model,
                                    addfunccol = &quot;computed.afv&quot;,
                                    control = list(trunc.pseudo=100)))
    #Predict points used for evaluation with the model trained with the 
    #calibration data set 
    PredEval &lt;- predict.glmssn(CalibSsn, &quot;_MissingObs_&quot;)
    #Extract predictions and transform from logit to probabilities 
    SSNProb &lt;- function(p)
    {
      #&quot;p&quot;: predictions from predict.glmssn
      logit &lt;- getPreds(p, pred.type = &quot;pred&quot;)
      prob &lt;- 1/(1+exp(-logit[,2]))
      return(prob)
    }
    PredProbEval &lt;- SSNProb(PredEval) 
    #Extract ids and observed presence-absences of points used for evaluation
    obsPresAbs &lt;- getSSNdata.frame(ssn_sp_i) %&gt;%
      filter(stream %in% EvaIds) %&gt;%
      select(stream,pres_abs)
    
    #Evaluation metrics
    idsPresabsProb &lt;- data.frame(obsPresAbs,PredProbEval)
    TSS &lt;- eval_mod(idsPresabsProb)$performance[5,2]
    AUC &lt;- eval_mod(idsPresabsProb)$performance[6,2]
    th &lt;- eval_mod(idsPresabsProb)$threshold[1,2]
    thres[,r] &lt;- th
    perform[,r] &lt;- c(TSS, AUC)
    if (AUC &gt; 0.7 &amp; TSS &gt; 0.7){
    #Predict on complete data set
    PredAll &lt;- predict.glmssn(CalibSsn, &quot;pred_sites&quot;)
    PredProb[,r] &lt;- SSNProb(PredAll)
    
    #Binary transformation 
    presabs &lt;- ifelse(PredProb[,r] &gt;= th,1,0)
    #Save  AUC, TSS, thresholds and predictions of models with AUC and TSS &gt; 0.7
    
      write.csv(EvaIds, row.names = F, paste0(output_path,&quot;/eva_ssn_&quot;,r,&quot;.csv&quot;))
      write.csv(AUC, row.names = F, paste0(output_path,&quot;/auc_ssn_&quot;,r,&quot;.csv&quot;))
      write.csv(TSS, row.names = F, paste0(output_path,&quot;/tss_ssn_&quot;,r,&quot;.csv&quot;))
      write.csv(th, row.names = F, paste0(output_path,&quot;/th_ssn_&quot;,r,&quot;.csv&quot;))
      write.csv(PredProb[,r], row.names = F, paste0(output_path,&quot;/pred_ssn_&quot;,r,&quot;.csv&quot;))
      write.csv(presabs, row.names = F, paste0(output_path,&quot;/presabs_ssn_&quot;,r,&quot;.csv&quot;))
    }
  
    } , error=function(e){}) 
    } 

  }, error=function(e){})
    
  }) 

 
}
                        
</pre></div>
</div>
</section>
<section id="model-ensamble">
<h3><span class="section-number">2.7.4.2. </span>5.2. Model ensamble<a class="headerlink" href="#model-ensamble" title="Permalink to this headline"></a></h3>
<div class="highlight-{r eval=FALSE} notranslate"><div class="highlight"><pre><span></span>#Ensemble model

library(dplyr)
library(sf)
library(raster)
setwd(&quot;C:/Users/torres/Nextcloud/FBAC&quot;)

# Function to create an ensemble prediction based on different methods
# &quot;ids&quot;: unique identifier for each observation in &quot;prob&quot;
# &quot;prob&quot;: data frame with predicted probabilities from different models.
# Each column in the data frame corresponds to a model
# &quot;occurr&quot;: data frame. Ids on the first column, occurrences (presence / absence)
# in the second.
# &quot;evalids&quot;: data frame with occurrence ids used for evaluation. Each column 
# correspond to an independent model.
# &quot;perform&quot;:  AUC to use as weight in weighted mean probability ensemble model. 
# Each column correspond to a single model.


ensem_mod &lt;- function(ids,
                      prob,
                      presabs,
                      occurr,
                      evalids
                      )
  {

  
## Mean ensemble model
  #Mean
  MeanEns &lt;- apply(prob, 1, mean, na.rm=T)
  #Coefficient of variation of the mean probabilities 
  cv &lt;- function (x) (sqrt(var(x, na.rm = T) / length(x)))/ mean(x, na.rm = T) 
  CvMeanEns &lt;- apply(prob, 1, cv)

## Weighted mean probability ensemble model 
  
  ProbAUC &lt;- matrix(nrow = nrow(prob), ncol = ncol(prob))
  for (i in 1:ncol(prob)) {
    ProbAUC[,i] &lt;- prob[,i] * perform[,i]
  }
  num &lt;- apply(ProbAUC, 1, sum)
  div &lt;- sum(perform[1,])
  WMeanEns &lt;- num / div
  
## Committee average ensemble model
   ComAvgEns &lt;- apply(presabs, 1, mean, na.rm=T)
### Evaluation 
  colnames(occurr)[1]&lt;-&quot;ids&quot;
  EvalMeanEns &lt;- matrix(ncol = ncol(evalids), nrow = 7)
  ThreshMeanEns &lt;- vector(length = ncol(evalids))
  #EvalWMeanEns &lt;- matrix(ncol = ncol(evalids), nrow = 7)
  #ThreshWMeanEns &lt;- vector(length = ncol(evalids))
  EvalComAvgEns &lt;- matrix(ncol = ncol(evalids), nrow = 7)
  ThreshComAvgEns &lt;- vector(length = ncol(evalids))
  for (i in 1:ncol(evalids)) {
    #Set of occurrences for evaluation
    EvalSet &lt;- occurr %&gt;%
      filter(ids %in% evalids[,i])
    #Set of probabilities for evaluation from MeanEnsem and WMeanEns
    MeanEns2 &lt;- data.frame(ids, MeanEns)%&gt;%
      filter(ids %in% evalids[,i])
    #WMeanEns2 &lt;- data.frame(ids, WMeanEns)%&gt;%
      #filter(ids %in% evalids[,i])
    ComAvgEns2 &lt;- data.frame(ids, ComAvgEns)%&gt;%
      filter(ids %in% evalids[,i])
    #Bind occurrences and probabilities
    eval_input_mean &lt;- EvalSet %&gt;%
      inner_join(MeanEns2, by = c(&quot;ids&quot; = &quot;ids&quot;))
    #eval_input_wmean &lt;- EvalSet %&gt;%
      #inner_join(WMeanEns2, by = c(&quot;ids&quot; = &quot;ids&quot;))
    eval_input_cavg &lt;- EvalSet %&gt;%
      inner_join(ComAvgEns2, by = c(&quot;ids&quot; = &quot;ids&quot;))
    #Performance metrics
    EvalMeanEns[,i] &lt;- eval_mod(eval_input_mean)$performance[,2]
    #EvalWMeanEns[,i] &lt;- eval_mod(eval_input_wmean)$performance[,2]
    EvalComAvgEns[,i] &lt;- eval_mod(eval_input_cavg)$performance[,2]
    #Threshold
    ThreshMeanEns[i] &lt;- eval_mod(eval_input_mean)$threshold[1,2]
    #ThreshWMeanEns[i] &lt;- eval_mod(eval_input_wmean)$threshold[1,2]
    ThreshComAvgEns[i] &lt;- eval_mod(eval_input_cavg)$threshold[1,2]
  }
  
  #Performance metrics. Mean in the last column
  Metrics &lt;- c(&quot;Sensitivity&quot;, &quot;Specificity&quot;, &quot;Omission&quot;, &quot;Commission&quot;, &quot;TSS&quot;, &quot;AUC_ROC&quot;, &quot;AUC_PRG&quot;)
  mean_metrics_m &lt;- apply(EvalMeanEns,1,mean, na.rm=T) 
  #mean_metrics_wm &lt;- apply(EvalWMeanEns,1,mean, na.rm=T)
  mean_metrics_ca &lt;- apply(EvalComAvgEns,1,mean, na.rm=T)
  EvalMeanEns &lt;- data.frame(Metrics,EvalMeanEns, mean_metrics_m)
  #EvalWMeanEns &lt;- data.frame(Metrics,EvalWMeanEns, mean_metrics_wm)
  EvalComAvgEns &lt;- data.frame(Metrics, EvalComAvgEns, mean_metrics_ca)
## Binary mean ensemble model
  tm &lt;- mean(ThreshMeanEns, na.rm=T)
  BinMeanEns &lt;- ifelse(MeanEns &gt;= tm,1,0)
## Binary weighted mean probability ensemble model
  #twm &lt;- mean(ThreshWMeanEns, na.rm=T)
  #BinWMeanEns &lt;- ifelse(WMeanEns &gt;= twm,1,0)
## Binary committee average ensemble model
  tca &lt;- mean(ThreshComAvgEns, na.rm=T)
  BinComAvgEns &lt;- ifelse(ComAvgEns &gt;= tca,1,0)

## Bind results
  EnsPred &lt;- data.frame(ids, MeanEns, CvMeanEns, BinMeanEns,  ComAvgEns, BinComAvgEns)
  
## Function output
 output &lt;- list(EnsPred, EvalMeanEns, EvalComAvgEns, 
                ThreshMeanEns, ThreshComAvgEns,
                tm, tca)
 return(output) 
}

#Get the names of files. Will be used to save results
files_names &lt;- list.files(path = &quot;./FBAC/data/SDM/output/indepModels&quot;,full.names = FALSE)
#Set the path to save the results
pathOutput &lt;- &quot;./FBAC/data/SDM/output/ensemble/&quot;
#Input path
pathInput &lt;- &quot;./FBAC/data/SDM/output/indepModels/&quot;

for (sp in 1:length(files_names)) {
  
      #Ids for prediction sites
      ids &lt;- read.csv(paste0(&quot;./FBAC/data/SDM/input/pred_sites/pred_sites.csv&quot;))$stream
      #Predicted probabilities from independent model algorithms
      filesProb &lt;- list.files(path = paste0(pathInput,files_names[sp]), 
                              pattern = &quot;.*pred.*\\.csv$&quot;,
                              full.names = T)
      prob &lt;- lapply(filesProb, read.csv)%&gt;%
        data.frame()
      #Presence absences predicted from independent model algorithms
      filesPresAbs &lt;- list.files(path = paste0(pathInput,files_names[sp]), 
                              pattern = &quot;.*presabs.*\\.csv$&quot;,
                              full.names = T)
      presabs &lt;- lapply(filesPresAbs, read.csv)%&gt;%
        data.frame()
      #Data set with occurrence records
      occurr &lt;- read.csv(paste0(&quot;./FBAC/data/SDM/input/occurr/&quot;,files_names[sp],&quot;/&quot;,&quot;occurr.csv&quot;))
      #Data frame with ids of occurrences used for evaluation
      FilesEvalIds &lt;- list.files(path = paste0(pathInput,files_names[sp]), 
                                 pattern = &quot;.*eva.*\\.csv$&quot;,
                                 full.names = T)
      evalids &lt;- lapply(FilesEvalIds, read.csv)%&gt;%
        data.frame()
      #Performance (AUC) from independent model algorithms
      filesPerform &lt;- list.files(path = paste0(pathInput,files_names[sp]), 
                                 pattern = &quot;.*auc.*\\.csv$&quot;,
                                 full.names = T)
      perform &lt;- lapply(filesPerform, read.csv)%&gt;%
        data.frame()
      #Ensemble model
      occurr2 &lt;- occurr %&gt;%
        dplyr::select(stream, pres_abs)
      ens &lt;- ensem_mod (ids, prob, presabs, occurr2, evalids, perform)
      
      #Export results
      tax &lt;- occurr %&gt;%
        dplyr::select(species, fam, ord, clas)
      EnsProb &lt;- ens[[1]] 
      EnsProb$species &lt;- tax[1,1]
      EnsProb$familiy &lt;- tax[1,2]
      EnsProb$order &lt;- tax[1,3]
      EnsProb$class &lt;- tax[1,4]
      MeanEnsEval &lt;- ens[[2]]
      WMeanEnsEval &lt;- ens[[3]]
      ComAvgEnsEval &lt;- ens[[4]]
      MeanEnsThresh &lt;- ens[[5]]
      WMeanEnsThresh &lt;- ens[[6]]
      ComAvgEnsThresh &lt;- ens[[7]]
      print(paste0(&quot;Export results for &quot;, files_names[sp]))
      
      outputpath2 &lt;- paste0(&quot;./FBAC/data/SDM/output/ensemble/&quot;,files_names[sp])
      
      ifelse(!dir.exists(outputpath2), dir.create(outputpath2), FALSE)
      
      #write.csv(MeanEnsThresh, row.names = F, paste0(outputpath2, &quot;/mean_ens_thres.csv&quot;))
      # write.csv(WMeanEnsThresh, row.names = F, paste0(outputpath2,&quot;/wmean_ens_thres.csv&quot;))
      # write.csv(ComAvgEnsThresh, row.names = F, paste0(outputpath2,&quot;/ca_ens_thres.csv&quot;))
      # 
      # write.csv(MeanEnsEval, row.names = F, paste0(outputpath2, &quot;/mean_ens_perform.csv&quot;))
      # write.csv(WMeanEnsEval, row.names = F, paste0(outputpath2, &quot;/wmean_ens_perform.csv&quot;))
      # write.csv(ComAvgEnsEval, row.names = F, paste0(outputpath2, &quot;/ca_ens_perform.csv&quot;))
       
      #write.csv(EnsProb, row.names = F, paste0(outputpath2, &quot;/pred.csv&quot;))
      #Map with predictions
      #Vector
      #rivers &lt;- st_read(&quot;./FBAC/data/SDM/input/streams_v.gpkg&quot;)%&gt;%
      #   inner_join(EnsProb, by = c(&quot;stream&quot; = &quot;ids&quot;))
      # 
      # st_write(rivers, paste0(outputpath2,&quot;/dist_rivers.gpkg&quot;),
      #          driver = &quot;GPKG&quot;, append = F, quiet= T)
       sub_basins &lt;- st_read(&quot;./FBAC/data/SDM/input/sub_basins_vectorized.gpkg&quot;)%&gt;%
         inner_join(EnsProb, by = c(&quot;Sub_basinID&quot; = &quot;ids&quot;))
      st_write(sub_basins, paste0(outputpath2,&quot;/&quot;,files_names[sp],&quot;.gpkg&quot;),
               driver = &quot;GPKG&quot;, append = F, quiet= T)
    
}
</pre></div>
</div>
<p><img alt="../../_images/richness.png" src="../../_images/richness.png" />
<em>Figure 11. Richness of freshwater species across Cuba predicted with a Spatial Linear Stream Network model. Top 10 species richness sub-basins are outlined.</em></p>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="Species_Distribution_Model_with_Random_Forest_Afroditi_Grigoropoulou.html" class="btn btn-neutral float-left" title="2.5. Afroditi Grigoropoulou: Species Distribution Model with Random Forest" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="Modeling_debris_flow_source_areas_Txomin_Bornaetxea.html" class="btn btn-neutral float-right" title="2.8. Txomin Bornaetxea: Modeling debris flow source areas" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, Giuseppe Amatulli.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>