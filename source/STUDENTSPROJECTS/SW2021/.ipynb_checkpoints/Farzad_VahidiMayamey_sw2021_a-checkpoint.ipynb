{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3293211",
   "metadata": {},
   "source": [
    "# Calculating landcover distribution & vegetation extraction\n",
    "**Farzad Vahidi Mayamey**\t\n",
    "\n",
    "**Aim of the studies**\n",
    "1. Calculating landcover distribution in our wetlands based on 10 m landcover map of Sweden\n",
    "2. Open water and flooded vegetation extraction in one of our wetlands."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c72b53c",
   "metadata": {},
   "source": [
    "## Calculating landcover distribution\n",
    "we use two different layer:\n",
    "1. [National landcover map of Sweden in 10m resolution](https://www.swedishepa.se/State-of-the-environment/Maps-and-map-services/National-Land-Cover-Database/) (above picture)\n",
    "2. [vector layer of Ramsar sites in Sweden](https://rsis.ramsar.org/ris-search/?f[0]=regionCountry_en_ss%3ASweden) (below picture)\n",
    "\n",
    "<img src='Farzad_VahidiMayamey_sw2021_1.png' width=\"400\">\n",
    "\\\\\n",
    "<img src='Farzad_VahidiMayamey_sw2021_2.png' width=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3442a3d3",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "gdalinfo nmd2018bas_ogeneraliserad_v1_1.tif | more"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454c66bf",
   "metadata": {},
   "source": [
    "As NoData Value is not assigned, we assign nodata value = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67977703",
   "metadata": {},
   "source": [
    "we create the shapefile of each wetland by using ```$ split vector layer``` tool in QGIS to clip our landcover by this layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da3e98d",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "for file in rms/*.gpkg; do echo $file; \n",
    "filename=$(basename $file .gpkg); \n",
    "gdalwarp -overwrite -srcnodata 0 -dstnodata 0 -crop_to_cutline -cutline $file nmd2018bas_ogeneraliserad_v1_1.tif clipped/${filename}.tif\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5117c0",
   "metadata": {},
   "source": [
    "Now that we have our clipped land cover we can calculate the histogram (in percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929f09d0",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "for file in clipped/*.tif; do \n",
    "echo $file; filename=$(basename $file .tif); \n",
    "pkstat -hist -rel -src_min 2 -src_max 128 -i $file > hist/${filename}.txt\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d96add",
   "metadata": {},
   "source": [
    "Now we have the text file of our histograms we can extract our desired classes for each of our 67 wetlands\n",
    "- we have 25 classess in total\n",
    "- 7 of the classess are our main interest\n",
    "\n",
    "<img src='Farzad_VahidiMayamey_sw2021_3.png' width=\"500\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198c8d96",
   "metadata": {},
   "source": [
    "Extract all 25 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b7ee6e",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "#printf \"%s %.3f\\n\", $1, $2\n",
    "for file in hist/*.txt; do echo $file; filename=$(basename $file .txt);\n",
    "awk '{ if($1==111||$1==112||$1==113||$1==114||$1==115||$1==116||$1==117||$1==118||$1==121||$1==122||$1==123||$1==124||$1==125||$1==126||$1==127||$1==128||$1==2||$1==3||$1==41||$1==42||$1==51||$1==52||$1==53||$1==61||$1==62) print}' $file > class_25/${filename}.txt;done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7723a208",
   "metadata": {},
   "source": [
    "Extract 7 main classess of our interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727f8eb9",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "for file in hist/*.txt; do echo $file; filename=$(basename $file .txt);\n",
    "    awk '$1==111 || $1==112 || $1==113 || $1==114 ||$1==115 || $1==116 ||$1==117 || $1==118 {sum1+= $2} \n",
    "$1==121 || $1==122 || $1==123 || $1==124 ||$1==125 || $1==126 ||$1==127 || $1==128 {sum2+= $2} \n",
    "$1==2 {sum3+= $2} \n",
    "$1==3 {sum4+= $2} \n",
    "$1==41 || $1==42 {sum5+= $2} \n",
    "$1==51 || $1==52 || $1==53 {sum6+= $2} \n",
    "$1==61 || $1==62 {sum7+= $2} \n",
    "END{print (\"1.1 \"sum1); print (\"1.2 \"sum2); print(\"2 \"sum3); print(\"3 \"sum4); print(\"4 \"sum5); print(\"5 \"sum6); print(\"6 \"sum7)}' $file > class_7/${filename}.txt;done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to add header to each of the text files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a1fffb",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "for file in class_7/*.txt; do echo $file; filename=$(basename $file .txt);\n",
    "awk 'BEGIN{print \"Class Ratio\"}1' $file > head/${filename}.txt; done #The 1 is to indicate to print every line of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68ffdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a781a96",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "\n",
    "file_location = os.path.join('class_7', '*.txt')\n",
    "filenames = glob.glob(file_location)\n",
    "\n",
    "\n",
    "class_ = ['Forest not on wetland', 'Forest on wetland',\n",
    "          'Open wetland','Arable land', 'Other openland', 'Artificial surfaces',\n",
    "          'Water']\n",
    "\n",
    "for f in filenames:\n",
    "    ratio = []\n",
    "    \n",
    "    outfile = open(f,'r')\n",
    "    for line in outfile:\n",
    "    \tData = [i for i in line.split()]\n",
    "    \tNew_Data= [ j for j in Data[1].split()]\n",
    "    \tratio.append(New_Data[0])\n",
    "    outfile.close()\n",
    "    \n",
    "    file_name = os.path.basename(f)\n",
    "    file_name=os.path.splitext(file_name)[0]\n",
    "    print(file_name)\n",
    "    \n",
    "    ratio = [float(i) for i in ratio]\n",
    "    #print(ratio)\n",
    "    colors = ['green', 'lime', 'mediumpurple', 'khaki','orange', 'red', 'blue']\n",
    "    explode = [0, 0.01, 0.01, 0, 0, 0, 0.01]\n",
    "    # plotting pie chart\n",
    "    def my_autopct(pct):\n",
    "        return ('%.2f%%' % pct) if pct > 5 else ''\n",
    "    \n",
    "    plt.pie(ratio, colors = colors, startangle = 90, explode = explode,\n",
    "    \t\t shadow = False, autopct=my_autopct )\n",
    "    \n",
    "    plt.title(label=file_name,  loc='center')\n",
    "    ratio_r =  [round(num, 2) for num in ratio]\n",
    "    labels = ['{0} - {1} %'.format(i, j) for i, j in zip(class_,ratio_r)]\n",
    "    plt.legend( labels, loc='lower left', bbox_to_anchor=(-0.15, -.15), fontsize=7)\n",
    "    plt.axis('equal')\n",
    "    #plt.tight_layout()\n",
    "    file_name_ext=os.path.splitext(file_name)[0]+\".png\"\n",
    "    plt.savefig(file_name_ext, format=\"png\", dpi=300)\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c72b73",
   "metadata": {},
   "source": [
    "## Open water and flooded vegetation extraction\n",
    "\n",
    "\n",
    "### Open water extraction\n",
    "- Layers: SAR intensity sentinel-1 image. \n",
    "\n",
    "<img src='Farzad_VahidiMayamey_sw2021_4.png' width=\"400\"> \n",
    "\n",
    "data source: [Google Earth Engine](https://code.earthengine.google.com)\n",
    "         \n",
    "          \n",
    "we use thresholding method to extract open water from S1 layer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe33126",
   "metadata": {},
   "source": [
    "First we move all layers to the crs: EPSG:4326"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0b31a0",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm --force layers_reprj/*.tif\n",
    "for file in layers/*.tif; do echo $file; filename=$(basename $file .tif);\n",
    "gdalwarp -ot \"Float32\" -t_srs EPSG:4326 $file layers_reprj/${filename}_reprj.tif;done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ea9e92",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash \n",
    "#applying nodata value equal to zero\n",
    "for file in layers/*.tif; do echo $file; \n",
    "gdal_edit.py -a_nodata -3.39999995214436425e+38 $file;done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb60ec4",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm --force crop/*.tif\n",
    "for file in layers/*.tif; do echo $file; \n",
    "  filename=$(basename $file .tif)\n",
    "  gdalwarp -overwrite -te 14.6714649 58.2914991 14.9516494 58.4129513 -tr 0.000269494585236 -0.000269494585236 $file crop/${filename}_crop.tif \n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa334ae",
   "metadata": {},
   "source": [
    "we maskout values greater than **-23** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b9e765",
   "metadata": {},
   "source": [
    "<img src='picture5.png' width=\"400\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de666546",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pkgetmask -max -23 -data 2 -nodata 0 -ot Byte -i crop/SAR_VH_crop.tif -o crop/water.tif;\n",
    "gdalwarp -crop_to_cutline -cutline rms/ramsarid_23.gpkg crop/water.tif  crop/wat.tif; "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5758e916",
   "metadata": {},
   "source": [
    "### Flooded vegetation extraction by using unsupervised Kmean classification\n",
    "- Layers: 1. Coherence layer ( left picture)\n",
    "          2. slope layer (generated from SRTM DEM (right picture)\n",
    "\n",
    "<img src='Farzad_VahidiMayamey_sw2021_6.png' width=\"400\">  <img src='Farzad_VahidiMayamey_sw2021_7.png' width=\"400\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96abd283",
   "metadata": {},
   "source": [
    "orfeo kmean clustering toolbox could not handle **nan** values and alsso give us warning for **nodatavalue=-3.39999995214436425e+38** \n",
    "by the following code we solve this two problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8d8b21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "#crop the coherence, SAR, and slope .tif files by our wetland shape of interest to exclude the nan values\n",
    "gdalwarp -crop_to_cutline -overwrite -srcnodata -3.39999995214436425e+38 -dstnodata -999 -cutline rms/ramsarid_23.gpkg crop/slope_crop.tif  crop/slope_crop_ready.tif; \n",
    "gdalwarp -crop_to_cutline -overwrite -srcnodata -3.39999995214436425e+38 -dstnodata -999 -cutline rms/ramsarid_23.gpkg crop/coherence_crop.tif  crop/coherence_crop_ready.tif "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed3edcc",
   "metadata": {},
   "source": [
    "We want to build stack of 2 layers before doing unsupervised classification: **SAR coherence** and **SRTM DEM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884fd8f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# stck the tif\n",
    "gdalbuildvrt -overwrite -separate crop/stack.vrt crop/coherence_crop_ready.tif crop/slope_crop_ready.tif\n",
    "gdalinfo -mm crop/stack.vrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727130fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# unsupervised classification\n",
    "~/OTB/superbuild_install/bin/otbcli_KMeansClassification -in crop/stack.vrt -ts 1000 -nc 15 -maxit 1000 -out crop/ClassificationFilterOutput.tif uint8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba17c52",
   "metadata": {},
   "source": [
    "In the following code we select the cluster with highest coherence **(cluster n. 12)**\n",
    "\n",
    "<img src='Farzad_VahidiMayamey_sw2021_8.png' width=\"400\">  <img src='Farzad_VahidiMayamey_sw2021_9.png' width=\"400\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff983de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pkgetmask -max 12 -min 12 -data 1 -nodata 0 -ot Byte -i crop/ClassificationFilterOutput.tif -o crop/veg.tif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ad6fcb",
   "metadata": {},
   "source": [
    "Now we want to calculate number of water pixels and flooded Vegetation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f985a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "#convert .tif to .txt\n",
    "gdal_translate -of XYZ crop/wat.tif crop/wat.txt\n",
    "gdal_translate -of XYZ crop/veg.tif crop/veg.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165cc7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#calculating number of pixels\n",
    "awk '{print$3}' crop/wat.txt | grep 2 | wc -l > crop/final.txt;\n",
    "awk '{print$3}' crop/veg.txt | grep 1 | wc -l >> crop/final.txt;\n",
    "cat crop/final.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d47af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert my_project.ipynb --to html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
